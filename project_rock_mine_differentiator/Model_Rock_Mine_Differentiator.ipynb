{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model that can Detect the difference between a Mine and a Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for reading the datast and for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv(\"sonar.all-data.csv\")\n",
    "    # X and y are np arrays\n",
    "    X = df[df.columns[0:60]].values\n",
    "    y = df[df.columns[60]]\n",
    "    \n",
    "    # Encode the dependent variable\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    #encoder.classes_\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y):\n",
    "    n_labels = len(y)\n",
    "    n_unique_labels = len(np.unique(y))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),y] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    # Hidden layer with sigmoid activated\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    # Hidden layer with sigmoid activated\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    # Hidden layer with sigmoid activated\n",
    "    layer_3 = tf.add(tf.matmul(layer_2,weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    # Hidden layer with RELU activated\n",
    "    layer_4 = tf.add(tf.matmul(layer_3,weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out']+biases['out'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "X, Y = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to mix up the rows\n",
    "X, Y = shuffle(X, Y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset into train and test part\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 60)\n",
      "(165, 2)\n",
      "(42, 60)\n",
      "(42, 2)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shape of the training and testing\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim = 60\n"
     ]
    }
   ],
   "source": [
    "# Define the important parametrs and variables to work with the tensors\n",
    "learning_rate = 0.02\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape = [1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"n_dim =\",n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of hidden layers and number of neurons for each layer\n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 70\n",
    "n_hidden_3 = 70\n",
    "n_hidden_4 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajitemmanuel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,[None,n_dim]) # None means any value\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_true = tf.placeholder(tf.float32,[None,n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4,n_class]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Saver object to save our model\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call your model defined\n",
    "y = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-ba49a8a1609b>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_true))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**\n",
      "(165, 60)\n",
      "(165, 2)\n",
      "(42, 60)\n",
      "(42, 2)\n",
      "epoch:  0  -  cost: 154.50835  -MSE: 19991.40560666472  -Train Accuracy:  0.45454547\n",
      "epoch:  1  -  cost: 21.127316  -MSE: 681.8202248506259  -Train Accuracy:  0.54545456\n",
      "epoch:  2  -  cost: 40.073597  -MSE: 1508.3353055975604  -Train Accuracy:  0.45454547\n",
      "epoch:  3  -  cost: 21.209328  -MSE: 671.5613075662279  -Train Accuracy:  0.54545456\n",
      "epoch:  4  -  cost: 15.536594  -MSE: 345.5052856372247  -Train Accuracy:  0.45454547\n",
      "epoch:  5  -  cost: 20.76442  -MSE: 627.8036895673434  -Train Accuracy:  0.54545456\n",
      "epoch:  6  -  cost: 5.430752  -MSE: 139.14671651622206  -Train Accuracy:  0.45454547\n",
      "epoch:  7  -  cost: 19.650862  -MSE: 555.6675035201663  -Train Accuracy:  0.54545456\n",
      "epoch:  8  -  cost: 1.1427866  -MSE: 94.30424250004391  -Train Accuracy:  0.47878787\n",
      "epoch:  9  -  cost: 2.3945506  -MSE: 99.98682797517696  -Train Accuracy:  0.56363636\n",
      "epoch:  10  -  cost: 13.961723  -MSE: 257.3109244071779  -Train Accuracy:  0.45454547\n",
      "epoch:  11  -  cost: 5.835516  -MSE: 121.50660978784524  -Train Accuracy:  0.54545456\n",
      "epoch:  12  -  cost: 7.7278194  -MSE: 126.7947173636515  -Train Accuracy:  0.45454547\n",
      "epoch:  13  -  cost: 6.7733045  -MSE: 128.2084586276354  -Train Accuracy:  0.54545456\n",
      "epoch:  14  -  cost: 4.0587  -MSE: 80.96007915033385  -Train Accuracy:  0.45454547\n",
      "epoch:  15  -  cost: 7.200364  -MSE: 130.7092531540477  -Train Accuracy:  0.54545456\n",
      "epoch:  16  -  cost: 1.8078681  -MSE: 62.4909999469091  -Train Accuracy:  0.44848484\n",
      "epoch:  17  -  cost: 6.189066  -MSE: 109.9909991633814  -Train Accuracy:  0.54545456\n",
      "epoch:  18  -  cost: 1.5235734  -MSE: 56.7059332608591  -Train Accuracy:  0.46060607\n",
      "epoch:  19  -  cost: 4.861667  -MSE: 87.77881992047101  -Train Accuracy:  0.54545456\n",
      "epoch:  20  -  cost: 1.7740625  -MSE: 53.076670208546915  -Train Accuracy:  0.45454547\n",
      "epoch:  21  -  cost: 4.400371  -MSE: 78.16040530684306  -Train Accuracy:  0.54545456\n",
      "epoch:  22  -  cost: 1.3978093  -MSE: 47.73336274186634  -Train Accuracy:  0.46666667\n",
      "epoch:  23  -  cost: 3.4019165  -MSE: 64.13059433721904  -Train Accuracy:  0.54545456\n",
      "epoch:  24  -  cost: 1.6184323  -MSE: 44.28169642378659  -Train Accuracy:  0.45454547\n",
      "epoch:  25  -  cost: 3.0497265  -MSE: 57.11496719917215  -Train Accuracy:  0.54545456\n",
      "epoch:  26  -  cost: 1.3973315  -MSE: 39.6543224188687  -Train Accuracy:  0.46666667\n",
      "epoch:  27  -  cost: 2.4664426  -MSE: 49.24135309889134  -Train Accuracy:  0.54545456\n",
      "epoch:  28  -  cost: 1.410688  -MSE: 36.64798818886234  -Train Accuracy:  0.45454547\n",
      "epoch:  29  -  cost: 2.0882902  -MSE: 43.69773106011372  -Train Accuracy:  0.54545456\n",
      "epoch:  30  -  cost: 1.3220577  -MSE: 33.515363279855805  -Train Accuracy:  0.46060607\n",
      "epoch:  31  -  cost: 1.7380183  -MSE: 38.6357423002123  -Train Accuracy:  0.54545456\n",
      "epoch:  32  -  cost: 1.2627555  -MSE: 30.870403134340524  -Train Accuracy:  0.46060607\n",
      "epoch:  33  -  cost: 1.4709533  -MSE: 34.75598890530747  -Train Accuracy:  0.54545456\n",
      "epoch:  34  -  cost: 1.1541911  -MSE: 28.349768824430846  -Train Accuracy:  0.47272727\n",
      "epoch:  35  -  cost: 1.2558066  -MSE: 31.32943390966164  -Train Accuracy:  0.55151516\n",
      "epoch:  36  -  cost: 1.0588781  -MSE: 26.31228357796842  -Train Accuracy:  0.4848485\n",
      "epoch:  37  -  cost: 1.092535  -MSE: 28.767733396026117  -Train Accuracy:  0.55757576\n",
      "epoch:  38  -  cost: 0.9670217  -MSE: 24.711097858147262  -Train Accuracy:  0.5272727\n",
      "epoch:  39  -  cost: 0.97128046  -MSE: 26.859041217548327  -Train Accuracy:  0.55151516\n",
      "epoch:  40  -  cost: 0.8819198  -MSE: 23.393804930895055  -Train Accuracy:  0.54545456\n",
      "epoch:  41  -  cost: 0.8746714  -MSE: 25.199683146677827  -Train Accuracy:  0.56969696\n",
      "epoch:  42  -  cost: 0.81991273  -MSE: 22.33371830217441  -Train Accuracy:  0.5939394\n",
      "epoch:  43  -  cost: 0.80454844  -MSE: 23.97923835205594  -Train Accuracy:  0.56969696\n",
      "epoch:  44  -  cost: 0.7651253  -MSE: 21.563069292448514  -Train Accuracy:  0.6\n",
      "epoch:  45  -  cost: 0.75042474  -MSE: 23.0572685091408  -Train Accuracy:  0.6\n",
      "epoch:  46  -  cost: 0.7218101  -MSE: 20.985893262014933  -Train Accuracy:  0.6121212\n",
      "epoch:  47  -  cost: 0.7114966  -MSE: 22.283653166433975  -Train Accuracy:  0.6181818\n",
      "epoch:  48  -  cost: 0.695657  -MSE: 20.52333895605232  -Train Accuracy:  0.6242424\n",
      "epoch:  49  -  cost: 0.68519396  -MSE: 21.65890990985767  -Train Accuracy:  0.630303\n",
      "epoch:  50  -  cost: 0.67217463  -MSE: 20.111901523595456  -Train Accuracy:  0.6121212\n",
      "epoch:  51  -  cost: 0.66358584  -MSE: 21.194670675058287  -Train Accuracy:  0.6363636\n",
      "epoch:  52  -  cost: 0.65340215  -MSE: 19.814991333091534  -Train Accuracy:  0.6121212\n",
      "epoch:  53  -  cost: 0.6448207  -MSE: 20.788290975141408  -Train Accuracy:  0.6424242\n",
      "epoch:  54  -  cost: 0.63778347  -MSE: 19.53782149372534  -Train Accuracy:  0.6242424\n",
      "epoch:  55  -  cost: 0.6311418  -MSE: 20.42524400852474  -Train Accuracy:  0.6484848\n",
      "epoch:  56  -  cost: 0.62543947  -MSE: 19.33271283338877  -Train Accuracy:  0.630303\n",
      "epoch:  57  -  cost: 0.619614  -MSE: 20.131141623435262  -Train Accuracy:  0.6606061\n",
      "epoch:  58  -  cost: 0.61309844  -MSE: 19.105942770936228  -Train Accuracy:  0.6424242\n",
      "epoch:  59  -  cost: 0.6099073  -MSE: 19.838008433866204  -Train Accuracy:  0.6666667\n",
      "epoch:  60  -  cost: 0.6039466  -MSE: 18.87548088854056  -Train Accuracy:  0.6484848\n",
      "epoch:  61  -  cost: 0.6019356  -MSE: 19.590961500146896  -Train Accuracy:  0.6727273\n",
      "epoch:  62  -  cost: 0.59635556  -MSE: 18.64742126437746  -Train Accuracy:  0.6484848\n",
      "epoch:  63  -  cost: 0.5946087  -MSE: 19.331049952487973  -Train Accuracy:  0.6969697\n",
      "epoch:  64  -  cost: 0.59020644  -MSE: 18.461309281268488  -Train Accuracy:  0.6545454\n",
      "epoch:  65  -  cost: 0.588305  -MSE: 19.090394478362338  -Train Accuracy:  0.6969697\n",
      "epoch:  66  -  cost: 0.58503956  -MSE: 18.239582857457  -Train Accuracy:  0.6545454\n",
      "epoch:  67  -  cost: 0.5832857  -MSE: 18.868590015238077  -Train Accuracy:  0.6969697\n",
      "epoch:  68  -  cost: 0.5803949  -MSE: 18.076347079625425  -Train Accuracy:  0.6545454\n",
      "epoch:  69  -  cost: 0.5788615  -MSE: 18.712102512216365  -Train Accuracy:  0.7030303\n",
      "epoch:  70  -  cost: 0.57627445  -MSE: 17.918459788507285  -Train Accuracy:  0.6606061\n",
      "epoch:  71  -  cost: 0.57469404  -MSE: 18.546797242420514  -Train Accuracy:  0.7090909\n",
      "epoch:  72  -  cost: 0.5725652  -MSE: 17.79615619074274  -Train Accuracy:  0.6606061\n",
      "epoch:  73  -  cost: 0.5720061  -MSE: 18.391683140700447  -Train Accuracy:  0.7151515\n",
      "epoch:  74  -  cost: 0.5700005  -MSE: 17.63095969030802  -Train Accuracy:  0.6727273\n",
      "epoch:  75  -  cost: 0.56985337  -MSE: 18.24282435275496  -Train Accuracy:  0.7151515\n",
      "epoch:  76  -  cost: 0.56782264  -MSE: 17.50017880497266  -Train Accuracy:  0.6727273\n",
      "epoch:  77  -  cost: 0.5675106  -MSE: 18.081874527198686  -Train Accuracy:  0.72121215\n",
      "epoch:  78  -  cost: 0.5651051  -MSE: 17.32343636968367  -Train Accuracy:  0.6727273\n",
      "epoch:  79  -  cost: 0.56503546  -MSE: 17.953326716334328  -Train Accuracy:  0.72727275\n",
      "epoch:  80  -  cost: 0.5629713  -MSE: 17.20539413320014  -Train Accuracy:  0.6666667\n",
      "epoch:  81  -  cost: 0.56257975  -MSE: 17.829338994895622  -Train Accuracy:  0.72727275\n",
      "epoch:  82  -  cost: 0.5604006  -MSE: 17.063307436386047  -Train Accuracy:  0.6666667\n",
      "epoch:  83  -  cost: 0.5597567  -MSE: 17.644900926872868  -Train Accuracy:  0.72727275\n",
      "epoch:  84  -  cost: 0.55733347  -MSE: 16.922771238204195  -Train Accuracy:  0.6787879\n",
      "epoch:  85  -  cost: 0.5569798  -MSE: 17.500713870003725  -Train Accuracy:  0.72727275\n",
      "epoch:  86  -  cost: 0.55466545  -MSE: 16.761465881637903  -Train Accuracy:  0.6787879\n",
      "epoch:  87  -  cost: 0.554273  -MSE: 17.332062400507578  -Train Accuracy:  0.72727275\n",
      "epoch:  88  -  cost: 0.5523687  -MSE: 16.57786922923728  -Train Accuracy:  0.6787879\n",
      "epoch:  89  -  cost: 0.5519713  -MSE: 17.157882255947325  -Train Accuracy:  0.72727275\n",
      "epoch:  90  -  cost: 0.5499861  -MSE: 16.41942841741465  -Train Accuracy:  0.6848485\n",
      "epoch:  91  -  cost: 0.54924536  -MSE: 16.994555570238965  -Train Accuracy:  0.72121215\n",
      "epoch:  92  -  cost: 0.5470106  -MSE: 16.248417289855883  -Train Accuracy:  0.6848485\n",
      "epoch:  93  -  cost: 0.5459275  -MSE: 16.811332989268685  -Train Accuracy:  0.72727275\n",
      "epoch:  94  -  cost: 0.5433235  -MSE: 16.086056747813874  -Train Accuracy:  0.6848485\n",
      "epoch:  95  -  cost: 0.5433588  -MSE: 16.621004643452153  -Train Accuracy:  0.73939395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  96  -  cost: 0.5404672  -MSE: 15.928145328799607  -Train Accuracy:  0.6909091\n",
      "epoch:  97  -  cost: 0.54100376  -MSE: 16.427572839035584  -Train Accuracy:  0.73939395\n",
      "epoch:  98  -  cost: 0.5378352  -MSE: 15.678566652723513  -Train Accuracy:  0.7090909\n",
      "epoch:  99  -  cost: 0.5383879  -MSE: 16.200561179795915  -Train Accuracy:  0.73939395\n",
      "epoch:  100  -  cost: 0.53576696  -MSE: 15.538291940509534  -Train Accuracy:  0.72121215\n",
      "epoch:  101  -  cost: 0.5358885  -MSE: 16.008807007547333  -Train Accuracy:  0.73939395\n",
      "epoch:  102  -  cost: 0.5335947  -MSE: 15.3474842628973  -Train Accuracy:  0.73333335\n",
      "epoch:  103  -  cost: 0.53328305  -MSE: 15.842582817651904  -Train Accuracy:  0.74545455\n",
      "epoch:  104  -  cost: 0.5309641  -MSE: 15.16244242895473  -Train Accuracy:  0.73333335\n",
      "epoch:  105  -  cost: 0.53124404  -MSE: 15.659153330038261  -Train Accuracy:  0.74545455\n",
      "epoch:  106  -  cost: 0.528353  -MSE: 14.964878899615474  -Train Accuracy:  0.73939395\n",
      "epoch:  107  -  cost: 0.5279073  -MSE: 15.431243587245016  -Train Accuracy:  0.73939395\n",
      "epoch:  108  -  cost: 0.5255004  -MSE: 14.733971280772732  -Train Accuracy:  0.74545455\n",
      "epoch:  109  -  cost: 0.5246314  -MSE: 15.215878338728858  -Train Accuracy:  0.73939395\n",
      "epoch:  110  -  cost: 0.5220408  -MSE: 14.52914762875622  -Train Accuracy:  0.74545455\n",
      "epoch:  111  -  cost: 0.52125454  -MSE: 15.042452615539725  -Train Accuracy:  0.74545455\n",
      "epoch:  112  -  cost: 0.518673  -MSE: 14.386472743267943  -Train Accuracy:  0.75151515\n",
      "epoch:  113  -  cost: 0.51727355  -MSE: 14.873458706996221  -Train Accuracy:  0.74545455\n",
      "epoch:  114  -  cost: 0.5149393  -MSE: 14.268891273415383  -Train Accuracy:  0.75151515\n",
      "epoch:  115  -  cost: 0.51347023  -MSE: 14.754985762198322  -Train Accuracy:  0.74545455\n",
      "epoch:  116  -  cost: 0.5107707  -MSE: 14.151900499306949  -Train Accuracy:  0.75151515\n",
      "epoch:  117  -  cost: 0.5088676  -MSE: 14.62808572436834  -Train Accuracy:  0.74545455\n",
      "epoch:  118  -  cost: 0.50501406  -MSE: 14.03824799638093  -Train Accuracy:  0.75757575\n",
      "epoch:  119  -  cost: 0.5041665  -MSE: 14.489929908358931  -Train Accuracy:  0.75151515\n",
      "epoch:  120  -  cost: 0.5017641  -MSE: 13.897242609791281  -Train Accuracy:  0.75757575\n",
      "epoch:  121  -  cost: 0.5011004  -MSE: 14.355909287971949  -Train Accuracy:  0.75757575\n",
      "epoch:  122  -  cost: 0.49880418  -MSE: 13.813336308615844  -Train Accuracy:  0.75151515\n",
      "epoch:  123  -  cost: 0.4983005  -MSE: 14.237823713345836  -Train Accuracy:  0.75757575\n",
      "epoch:  124  -  cost: 0.495034  -MSE: 13.691817681797758  -Train Accuracy:  0.76363635\n",
      "epoch:  125  -  cost: 0.49406096  -MSE: 14.11976284446267  -Train Accuracy:  0.75757575\n",
      "epoch:  126  -  cost: 0.4904142  -MSE: 13.583101716176099  -Train Accuracy:  0.77575755\n",
      "epoch:  127  -  cost: 0.48951107  -MSE: 14.00704767207868  -Train Accuracy:  0.76363635\n",
      "epoch:  128  -  cost: 0.48622775  -MSE: 13.501069011191444  -Train Accuracy:  0.77575755\n",
      "epoch:  129  -  cost: 0.48546535  -MSE: 13.917563826544134  -Train Accuracy:  0.76363635\n",
      "epoch:  130  -  cost: 0.48177508  -MSE: 13.434520643805026  -Train Accuracy:  0.7878788\n",
      "epoch:  131  -  cost: 0.4809677  -MSE: 13.806346999610712  -Train Accuracy:  0.75757575\n",
      "epoch:  132  -  cost: 0.47739017  -MSE: 13.351148949199265  -Train Accuracy:  0.7878788\n",
      "epoch:  133  -  cost: 0.47697186  -MSE: 13.71074662594686  -Train Accuracy:  0.75757575\n",
      "epoch:  134  -  cost: 0.47380745  -MSE: 13.292917088614455  -Train Accuracy:  0.7939394\n",
      "epoch:  135  -  cost: 0.47376865  -MSE: 13.636388880094303  -Train Accuracy:  0.76363635\n",
      "epoch:  136  -  cost: 0.47124073  -MSE: 13.247502351528984  -Train Accuracy:  0.7939394\n",
      "epoch:  137  -  cost: 0.47111887  -MSE: 13.575691337569229  -Train Accuracy:  0.76969695\n",
      "epoch:  138  -  cost: 0.46902037  -MSE: 13.193614984875916  -Train Accuracy:  0.7939394\n",
      "epoch:  139  -  cost: 0.46915376  -MSE: 13.530847637121632  -Train Accuracy:  0.76969695\n",
      "epoch:  140  -  cost: 0.46721825  -MSE: 13.174005574584582  -Train Accuracy:  0.7939394\n",
      "epoch:  141  -  cost: 0.46710718  -MSE: 13.498869299092297  -Train Accuracy:  0.77575755\n",
      "epoch:  142  -  cost: 0.46518943  -MSE: 13.119219950132813  -Train Accuracy:  0.7939394\n",
      "epoch:  143  -  cost: 0.46524775  -MSE: 13.462218008570533  -Train Accuracy:  0.77575755\n",
      "epoch:  144  -  cost: 0.46338302  -MSE: 13.085107827939293  -Train Accuracy:  0.8\n",
      "epoch:  145  -  cost: 0.46319094  -MSE: 13.411418917399612  -Train Accuracy:  0.77575755\n",
      "epoch:  146  -  cost: 0.46140733  -MSE: 13.032702341530406  -Train Accuracy:  0.8\n",
      "epoch:  147  -  cost: 0.46101466  -MSE: 13.37328707329859  -Train Accuracy:  0.7818182\n",
      "epoch:  148  -  cost: 0.45942628  -MSE: 13.017524836964542  -Train Accuracy:  0.8\n",
      "epoch:  149  -  cost: 0.45892274  -MSE: 13.342308070049036  -Train Accuracy:  0.7878788\n",
      "epoch:  150  -  cost: 0.45792714  -MSE: 12.988659733925445  -Train Accuracy:  0.8\n",
      "epoch:  151  -  cost: 0.45773476  -MSE: 13.320000753447603  -Train Accuracy:  0.7878788\n",
      "epoch:  152  -  cost: 0.45625198  -MSE: 12.93980406277702  -Train Accuracy:  0.8\n",
      "epoch:  153  -  cost: 0.45594326  -MSE: 13.291597579886973  -Train Accuracy:  0.7878788\n",
      "epoch:  154  -  cost: 0.45481238  -MSE: 12.91373726589539  -Train Accuracy:  0.8\n",
      "epoch:  155  -  cost: 0.45456463  -MSE: 13.270193730372913  -Train Accuracy:  0.7878788\n",
      "epoch:  156  -  cost: 0.4533202  -MSE: 12.881111898688186  -Train Accuracy:  0.8\n",
      "epoch:  157  -  cost: 0.45293567  -MSE: 13.260643578676495  -Train Accuracy:  0.7878788\n",
      "epoch:  158  -  cost: 0.45199022  -MSE: 12.861479450026293  -Train Accuracy:  0.8\n",
      "epoch:  159  -  cost: 0.45168018  -MSE: 13.260532425736926  -Train Accuracy:  0.7878788\n",
      "epoch:  160  -  cost: 0.4508641  -MSE: 12.864932411230045  -Train Accuracy:  0.8\n",
      "epoch:  161  -  cost: 0.45069417  -MSE: 13.245130130423062  -Train Accuracy:  0.7878788\n",
      "epoch:  162  -  cost: 0.45010412  -MSE: 12.862481818279255  -Train Accuracy:  0.8060606\n",
      "epoch:  163  -  cost: 0.449851  -MSE: 13.232609673145754  -Train Accuracy:  0.7878788\n",
      "epoch:  164  -  cost: 0.44920534  -MSE: 12.831694909767261  -Train Accuracy:  0.8121212\n",
      "epoch:  165  -  cost: 0.4496132  -MSE: 13.214030170921571  -Train Accuracy:  0.7939394\n",
      "epoch:  166  -  cost: 0.4491277  -MSE: 12.799696148074682  -Train Accuracy:  0.8121212\n",
      "epoch:  167  -  cost: 0.44972605  -MSE: 13.188339314994304  -Train Accuracy:  0.7939394\n",
      "epoch:  168  -  cost: 0.44918185  -MSE: 12.752012530966274  -Train Accuracy:  0.8121212\n",
      "epoch:  169  -  cost: 0.4495716  -MSE: 13.156440096785559  -Train Accuracy:  0.77575755\n",
      "epoch:  170  -  cost: 0.44915003  -MSE: 12.71490519584298  -Train Accuracy:  0.8060606\n",
      "epoch:  171  -  cost: 0.44974297  -MSE: 13.131548402214372  -Train Accuracy:  0.76969695\n",
      "epoch:  172  -  cost: 0.4489833  -MSE: 12.670660562602336  -Train Accuracy:  0.8060606\n",
      "epoch:  173  -  cost: 0.44964868  -MSE: 13.101564944782874  -Train Accuracy:  0.76969695\n",
      "epoch:  174  -  cost: 0.4496013  -MSE: 12.623084184186604  -Train Accuracy:  0.8060606\n",
      "epoch:  175  -  cost: 0.45015916  -MSE: 13.072812368326757  -Train Accuracy:  0.76969695\n",
      "epoch:  176  -  cost: 0.4489679  -MSE: 12.569402070732911  -Train Accuracy:  0.8060606\n",
      "epoch:  177  -  cost: 0.44902238  -MSE: 13.021575723108418  -Train Accuracy:  0.76969695\n",
      "epoch:  178  -  cost: 0.4474887  -MSE: 12.516070819368784  -Train Accuracy:  0.8121212\n",
      "epoch:  179  -  cost: 0.44743416  -MSE: 12.969611474770224  -Train Accuracy:  0.77575755\n",
      "epoch:  180  -  cost: 0.44579792  -MSE: 12.475516228368221  -Train Accuracy:  0.8121212\n",
      "epoch:  181  -  cost: 0.44559628  -MSE: 12.936411140736428  -Train Accuracy:  0.7818182\n",
      "epoch:  182  -  cost: 0.44388428  -MSE: 12.42732997266236  -Train Accuracy:  0.8121212\n",
      "epoch:  183  -  cost: 0.44340757  -MSE: 12.910018043689181  -Train Accuracy:  0.7818182\n",
      "epoch:  184  -  cost: 0.44169098  -MSE: 12.40552864352773  -Train Accuracy:  0.8121212\n",
      "epoch:  185  -  cost: 0.44111148  -MSE: 12.858428171070408  -Train Accuracy:  0.7818182\n",
      "epoch:  186  -  cost: 0.43941513  -MSE: 12.36269003699726  -Train Accuracy:  0.8242424\n",
      "epoch:  187  -  cost: 0.43846807  -MSE: 12.824943222842313  -Train Accuracy:  0.7818182\n",
      "epoch:  188  -  cost: 0.4368293  -MSE: 12.3526627350896  -Train Accuracy:  0.8242424\n",
      "epoch:  189  -  cost: 0.43555543  -MSE: 12.800083600400233  -Train Accuracy:  0.7878788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  190  -  cost: 0.4338882  -MSE: 12.326854711360003  -Train Accuracy:  0.8181818\n",
      "epoch:  191  -  cost: 0.43270528  -MSE: 12.775494273066164  -Train Accuracy:  0.7878788\n",
      "epoch:  192  -  cost: 0.43063012  -MSE: 12.334454549267955  -Train Accuracy:  0.8242424\n",
      "epoch:  193  -  cost: 0.42916384  -MSE: 12.737298137681787  -Train Accuracy:  0.8060606\n",
      "epoch:  194  -  cost: 0.42720652  -MSE: 12.297334697468866  -Train Accuracy:  0.830303\n",
      "epoch:  195  -  cost: 0.42570505  -MSE: 12.70375887619041  -Train Accuracy:  0.8060606\n",
      "epoch:  196  -  cost: 0.42379808  -MSE: 12.286407735858136  -Train Accuracy:  0.8363636\n",
      "epoch:  197  -  cost: 0.42239562  -MSE: 12.660205615383873  -Train Accuracy:  0.8121212\n",
      "epoch:  198  -  cost: 0.42071116  -MSE: 12.279374330895351  -Train Accuracy:  0.8363636\n",
      "epoch:  199  -  cost: 0.41932392  -MSE: 12.634830042518464  -Train Accuracy:  0.8121212\n",
      "epoch:  200  -  cost: 0.41805914  -MSE: 12.253048039150533  -Train Accuracy:  0.8363636\n",
      "epoch:  201  -  cost: 0.416432  -MSE: 12.581556513763003  -Train Accuracy:  0.8121212\n",
      "epoch:  202  -  cost: 0.4154493  -MSE: 12.241393944387358  -Train Accuracy:  0.8363636\n",
      "epoch:  203  -  cost: 0.41486895  -MSE: 12.567290519688656  -Train Accuracy:  0.8121212\n",
      "epoch:  204  -  cost: 0.41431108  -MSE: 12.209600169598119  -Train Accuracy:  0.8363636\n",
      "epoch:  205  -  cost: 0.4144001  -MSE: 12.553806842326223  -Train Accuracy:  0.8121212\n",
      "epoch:  206  -  cost: 0.41380593  -MSE: 12.212006415736244  -Train Accuracy:  0.8424242\n",
      "epoch:  207  -  cost: 0.414746  -MSE: 12.557651175916627  -Train Accuracy:  0.8121212\n",
      "epoch:  208  -  cost: 0.4139514  -MSE: 12.20332871272363  -Train Accuracy:  0.8363636\n",
      "epoch:  209  -  cost: 0.41499823  -MSE: 12.570668638946104  -Train Accuracy:  0.8060606\n",
      "epoch:  210  -  cost: 0.41409844  -MSE: 12.194763051858326  -Train Accuracy:  0.8363636\n",
      "epoch:  211  -  cost: 0.41518232  -MSE: 12.554412859071586  -Train Accuracy:  0.8060606\n",
      "epoch:  212  -  cost: 0.4144454  -MSE: 12.158249209749718  -Train Accuracy:  0.8424242\n",
      "epoch:  213  -  cost: 0.4161567  -MSE: 12.555608335670874  -Train Accuracy:  0.8\n",
      "epoch:  214  -  cost: 0.41547897  -MSE: 12.1776557661276  -Train Accuracy:  0.8424242\n",
      "epoch:  215  -  cost: 0.4173701  -MSE: 12.593598639775688  -Train Accuracy:  0.7878788\n",
      "epoch:  216  -  cost: 0.41627362  -MSE: 12.14825433877754  -Train Accuracy:  0.8424242\n",
      "epoch:  217  -  cost: 0.4180991  -MSE: 12.594482574670327  -Train Accuracy:  0.7878788\n",
      "epoch:  218  -  cost: 0.4172599  -MSE: 12.151512728111314  -Train Accuracy:  0.830303\n",
      "epoch:  219  -  cost: 0.41870898  -MSE: 12.56446327603945  -Train Accuracy:  0.7878788\n",
      "epoch:  220  -  cost: 0.41715172  -MSE: 12.089066140191338  -Train Accuracy:  0.830303\n",
      "epoch:  221  -  cost: 0.41885492  -MSE: 12.590250793861824  -Train Accuracy:  0.7878788\n",
      "epoch:  222  -  cost: 0.4176075  -MSE: 12.092718891052815  -Train Accuracy:  0.8181818\n",
      "epoch:  223  -  cost: 0.41942322  -MSE: 12.600560759635945  -Train Accuracy:  0.7939394\n",
      "epoch:  224  -  cost: 0.41826347  -MSE: 12.091263807524106  -Train Accuracy:  0.830303\n",
      "epoch:  225  -  cost: 0.41988844  -MSE: 12.576910609327618  -Train Accuracy:  0.7939394\n",
      "epoch:  226  -  cost: 0.4180474  -MSE: 12.040018156720784  -Train Accuracy:  0.830303\n",
      "epoch:  227  -  cost: 0.42009997  -MSE: 12.558625244377232  -Train Accuracy:  0.7939394\n",
      "epoch:  228  -  cost: 0.41832152  -MSE: 12.037256643725446  -Train Accuracy:  0.8363636\n",
      "epoch:  229  -  cost: 0.41992322  -MSE: 12.51620046543885  -Train Accuracy:  0.8\n",
      "epoch:  230  -  cost: 0.4178858  -MSE: 11.969698045617129  -Train Accuracy:  0.8363636\n",
      "epoch:  231  -  cost: 0.41911992  -MSE: 12.504387621137173  -Train Accuracy:  0.8\n",
      "epoch:  232  -  cost: 0.41678476  -MSE: 11.95045891623358  -Train Accuracy:  0.8363636\n",
      "epoch:  233  -  cost: 0.4175796  -MSE: 12.45179284962894  -Train Accuracy:  0.8\n",
      "epoch:  234  -  cost: 0.41554254  -MSE: 11.896929631323886  -Train Accuracy:  0.8363636\n",
      "epoch:  235  -  cost: 0.41618446  -MSE: 12.405009626022512  -Train Accuracy:  0.8\n",
      "epoch:  236  -  cost: 0.4120672  -MSE: 11.846921087745852  -Train Accuracy:  0.8363636\n",
      "epoch:  237  -  cost: 0.41259575  -MSE: 12.328325865440785  -Train Accuracy:  0.8\n",
      "epoch:  238  -  cost: 0.409315  -MSE: 11.791695334043265  -Train Accuracy:  0.8424242\n",
      "epoch:  239  -  cost: 0.4098198  -MSE: 12.296400942651985  -Train Accuracy:  0.7939394\n",
      "epoch:  240  -  cost: 0.40681463  -MSE: 11.774045523269782  -Train Accuracy:  0.8424242\n",
      "epoch:  241  -  cost: 0.40775442  -MSE: 12.247598471968498  -Train Accuracy:  0.7939394\n",
      "epoch:  242  -  cost: 0.40463087  -MSE: 11.73219697951974  -Train Accuracy:  0.8363636\n",
      "epoch:  243  -  cost: 0.40536976  -MSE: 12.188867873051716  -Train Accuracy:  0.7939394\n",
      "epoch:  244  -  cost: 0.40235358  -MSE: 11.685850615830654  -Train Accuracy:  0.8363636\n",
      "epoch:  245  -  cost: 0.40311658  -MSE: 12.156795656618002  -Train Accuracy:  0.8\n",
      "epoch:  246  -  cost: 0.40019912  -MSE: 11.667730512021697  -Train Accuracy:  0.8424242\n",
      "epoch:  247  -  cost: 0.40071684  -MSE: 12.150089973182109  -Train Accuracy:  0.8121212\n",
      "epoch:  248  -  cost: 0.39833972  -MSE: 11.665763813004633  -Train Accuracy:  0.8424242\n",
      "epoch:  249  -  cost: 0.39834806  -MSE: 12.140937323749538  -Train Accuracy:  0.8121212\n",
      "epoch:  250  -  cost: 0.3959317  -MSE: 11.647204875383897  -Train Accuracy:  0.8424242\n",
      "epoch:  251  -  cost: 0.39587727  -MSE: 12.10526675514519  -Train Accuracy:  0.8181818\n",
      "epoch:  252  -  cost: 0.3938699  -MSE: 11.619404163866507  -Train Accuracy:  0.8424242\n",
      "epoch:  253  -  cost: 0.39424646  -MSE: 12.088034779158345  -Train Accuracy:  0.8121212\n",
      "epoch:  254  -  cost: 0.39249066  -MSE: 11.59353584985371  -Train Accuracy:  0.8424242\n",
      "epoch:  255  -  cost: 0.39248943  -MSE: 12.05135495892475  -Train Accuracy:  0.8181818\n",
      "epoch:  256  -  cost: 0.39038935  -MSE: 11.58896996531836  -Train Accuracy:  0.8424242\n",
      "epoch:  257  -  cost: 0.39055225  -MSE: 12.069302088858304  -Train Accuracy:  0.8181818\n",
      "epoch:  258  -  cost: 0.3889939  -MSE: 11.596789735832223  -Train Accuracy:  0.8424242\n",
      "epoch:  259  -  cost: 0.38885087  -MSE: 12.035800846870622  -Train Accuracy:  0.8181818\n",
      "epoch:  260  -  cost: 0.3870867  -MSE: 11.596550705260121  -Train Accuracy:  0.8424242\n",
      "epoch:  261  -  cost: 0.38722235  -MSE: 12.055238111110416  -Train Accuracy:  0.8181818\n",
      "epoch:  262  -  cost: 0.38606432  -MSE: 11.58190737114971  -Train Accuracy:  0.8424242\n",
      "epoch:  263  -  cost: 0.38615978  -MSE: 12.032383909502965  -Train Accuracy:  0.8242424\n",
      "epoch:  264  -  cost: 0.38491744  -MSE: 11.591690649474499  -Train Accuracy:  0.8424242\n",
      "epoch:  265  -  cost: 0.38484338  -MSE: 12.05331076724452  -Train Accuracy:  0.8242424\n",
      "epoch:  266  -  cost: 0.3838741  -MSE: 11.581884637439751  -Train Accuracy:  0.8424242\n",
      "epoch:  267  -  cost: 0.3839026  -MSE: 12.026051849433356  -Train Accuracy:  0.8242424\n",
      "epoch:  268  -  cost: 0.38221288  -MSE: 11.570949724817655  -Train Accuracy:  0.8484849\n",
      "epoch:  269  -  cost: 0.38217685  -MSE: 12.027572690584364  -Train Accuracy:  0.8242424\n",
      "epoch:  270  -  cost: 0.38083035  -MSE: 11.548157978357157  -Train Accuracy:  0.8484849\n",
      "epoch:  271  -  cost: 0.38062775  -MSE: 12.008823290449012  -Train Accuracy:  0.8242424\n",
      "epoch:  272  -  cost: 0.3793309  -MSE: 11.539092364618394  -Train Accuracy:  0.8484849\n",
      "epoch:  273  -  cost: 0.37966338  -MSE: 11.983452205838644  -Train Accuracy:  0.8242424\n",
      "epoch:  274  -  cost: 0.3787923  -MSE: 11.500647768300691  -Train Accuracy:  0.8484849\n",
      "epoch:  275  -  cost: 0.37906  -MSE: 11.962216450889152  -Train Accuracy:  0.8242424\n",
      "epoch:  276  -  cost: 0.37759653  -MSE: 11.48068254933385  -Train Accuracy:  0.8484849\n",
      "epoch:  277  -  cost: 0.37783626  -MSE: 11.938080095364418  -Train Accuracy:  0.8242424\n",
      "epoch:  278  -  cost: 0.3768035  -MSE: 11.445058690629432  -Train Accuracy:  0.8484849\n",
      "epoch:  279  -  cost: 0.3771948  -MSE: 11.906040083789568  -Train Accuracy:  0.830303\n",
      "epoch:  280  -  cost: 0.37558585  -MSE: 11.40071159746696  -Train Accuracy:  0.8484849\n",
      "epoch:  281  -  cost: 0.37558132  -MSE: 11.866111362235472  -Train Accuracy:  0.830303\n",
      "epoch:  282  -  cost: 0.37415493  -MSE: 11.36606565927661  -Train Accuracy:  0.8484849\n",
      "epoch:  283  -  cost: 0.37433577  -MSE: 11.818326945924795  -Train Accuracy:  0.830303\n",
      "epoch:  284  -  cost: 0.3729041  -MSE: 11.319429874225225  -Train Accuracy:  0.8484849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  285  -  cost: 0.37318745  -MSE: 11.78873970779147  -Train Accuracy:  0.830303\n",
      "epoch:  286  -  cost: 0.37160712  -MSE: 11.297805706505864  -Train Accuracy:  0.8484849\n",
      "epoch:  287  -  cost: 0.3720607  -MSE: 11.73000218261239  -Train Accuracy:  0.830303\n",
      "epoch:  288  -  cost: 0.37063593  -MSE: 11.245520126947373  -Train Accuracy:  0.8484849\n",
      "epoch:  289  -  cost: 0.3709935  -MSE: 11.733000530215483  -Train Accuracy:  0.830303\n",
      "epoch:  290  -  cost: 0.36978742  -MSE: 11.26863714645892  -Train Accuracy:  0.8484849\n",
      "epoch:  291  -  cost: 0.3701947  -MSE: 11.733319619808041  -Train Accuracy:  0.830303\n",
      "epoch:  292  -  cost: 0.36900336  -MSE: 11.258387344129774  -Train Accuracy:  0.8484849\n",
      "epoch:  293  -  cost: 0.36962658  -MSE: 11.74672711571838  -Train Accuracy:  0.830303\n",
      "epoch:  294  -  cost: 0.36837605  -MSE: 11.2408360692739  -Train Accuracy:  0.8484849\n",
      "epoch:  295  -  cost: 0.36907777  -MSE: 11.736554927178773  -Train Accuracy:  0.830303\n",
      "epoch:  296  -  cost: 0.36732426  -MSE: 11.255384997363937  -Train Accuracy:  0.8484849\n",
      "epoch:  297  -  cost: 0.36809728  -MSE: 11.753624074969188  -Train Accuracy:  0.830303\n",
      "epoch:  298  -  cost: 0.36648482  -MSE: 11.274927242988149  -Train Accuracy:  0.8484849\n",
      "epoch:  299  -  cost: 0.3669031  -MSE: 11.751533070305602  -Train Accuracy:  0.830303\n",
      "epoch:  300  -  cost: 0.36499456  -MSE: 11.295183194259554  -Train Accuracy:  0.8484849\n",
      "epoch:  301  -  cost: 0.3652714  -MSE: 11.80304965573514  -Train Accuracy:  0.830303\n",
      "epoch:  302  -  cost: 0.3636074  -MSE: 11.35083749066413  -Train Accuracy:  0.8484849\n",
      "epoch:  303  -  cost: 0.36410955  -MSE: 11.80682699251245  -Train Accuracy:  0.8363636\n",
      "epoch:  304  -  cost: 0.36237738  -MSE: 11.373408845097698  -Train Accuracy:  0.8484849\n",
      "epoch:  305  -  cost: 0.36306888  -MSE: 11.845099993830345  -Train Accuracy:  0.830303\n",
      "epoch:  306  -  cost: 0.36124703  -MSE: 11.402058701904782  -Train Accuracy:  0.8484849\n",
      "epoch:  307  -  cost: 0.3616435  -MSE: 11.872453531134287  -Train Accuracy:  0.8363636\n",
      "epoch:  308  -  cost: 0.36014697  -MSE: 11.42427734337938  -Train Accuracy:  0.8484849\n",
      "epoch:  309  -  cost: 0.3605731  -MSE: 11.887489003263532  -Train Accuracy:  0.8363636\n",
      "epoch:  310  -  cost: 0.3588669  -MSE: 11.450239892770588  -Train Accuracy:  0.8484849\n",
      "epoch:  311  -  cost: 0.35944104  -MSE: 11.925500947483343  -Train Accuracy:  0.8363636\n",
      "epoch:  312  -  cost: 0.3579665  -MSE: 11.473609840706718  -Train Accuracy:  0.8484849\n",
      "epoch:  313  -  cost: 0.3582861  -MSE: 11.944202766025503  -Train Accuracy:  0.8424242\n",
      "epoch:  314  -  cost: 0.35695755  -MSE: 11.504461060721113  -Train Accuracy:  0.8484849\n",
      "epoch:  315  -  cost: 0.35695076  -MSE: 11.925913986162502  -Train Accuracy:  0.8363636\n",
      "epoch:  316  -  cost: 0.35538563  -MSE: 11.508738108409265  -Train Accuracy:  0.8484849\n",
      "epoch:  317  -  cost: 0.35570243  -MSE: 11.984365506560865  -Train Accuracy:  0.8363636\n",
      "epoch:  318  -  cost: 0.35443765  -MSE: 11.555095349337932  -Train Accuracy:  0.8484849\n",
      "epoch:  319  -  cost: 0.3546051  -MSE: 12.008427439848512  -Train Accuracy:  0.830303\n",
      "epoch:  320  -  cost: 0.35342783  -MSE: 11.594910046890803  -Train Accuracy:  0.8484849\n",
      "epoch:  321  -  cost: 0.35349038  -MSE: 12.051261897316495  -Train Accuracy:  0.8484849\n",
      "epoch:  322  -  cost: 0.35228702  -MSE: 11.638730959151266  -Train Accuracy:  0.8484849\n",
      "epoch:  323  -  cost: 0.35244825  -MSE: 12.087299487490856  -Train Accuracy:  0.8424242\n",
      "epoch:  324  -  cost: 0.35119268  -MSE: 11.66847944579849  -Train Accuracy:  0.8545455\n",
      "epoch:  325  -  cost: 0.3514217  -MSE: 12.111171942155325  -Train Accuracy:  0.8484849\n",
      "epoch:  326  -  cost: 0.35056955  -MSE: 11.68300215412298  -Train Accuracy:  0.8545455\n",
      "epoch:  327  -  cost: 0.35080323  -MSE: 12.128941509480894  -Train Accuracy:  0.8484849\n",
      "epoch:  328  -  cost: 0.3496066  -MSE: 11.70299275248797  -Train Accuracy:  0.8545455\n",
      "epoch:  329  -  cost: 0.3499685  -MSE: 12.144540752137573  -Train Accuracy:  0.8484849\n",
      "epoch:  330  -  cost: 0.3490234  -MSE: 11.729015252319554  -Train Accuracy:  0.8545455\n",
      "epoch:  331  -  cost: 0.34932342  -MSE: 12.179395476010457  -Train Accuracy:  0.8545455\n",
      "epoch:  332  -  cost: 0.34853554  -MSE: 11.736187961951257  -Train Accuracy:  0.8545455\n",
      "epoch:  333  -  cost: 0.34889838  -MSE: 12.194916901848842  -Train Accuracy:  0.8545455\n",
      "epoch:  334  -  cost: 0.34791264  -MSE: 11.74373672616438  -Train Accuracy:  0.8545455\n",
      "epoch:  335  -  cost: 0.34832615  -MSE: 12.195935694744893  -Train Accuracy:  0.8545455\n",
      "epoch:  336  -  cost: 0.3474156  -MSE: 11.75926408390285  -Train Accuracy:  0.8545455\n",
      "epoch:  337  -  cost: 0.3478417  -MSE: 12.219076736966112  -Train Accuracy:  0.8545455\n",
      "epoch:  338  -  cost: 0.34684497  -MSE: 11.778075255714375  -Train Accuracy:  0.8545455\n",
      "epoch:  339  -  cost: 0.34732  -MSE: 12.260082398160913  -Train Accuracy:  0.8545455\n",
      "epoch:  340  -  cost: 0.3466588  -MSE: 11.790837183172497  -Train Accuracy:  0.8545455\n",
      "epoch:  341  -  cost: 0.34702727  -MSE: 12.264863049376467  -Train Accuracy:  0.8545455\n",
      "epoch:  342  -  cost: 0.34643415  -MSE: 11.779907236637584  -Train Accuracy:  0.8606061\n",
      "epoch:  343  -  cost: 0.34720188  -MSE: 12.308699860251474  -Train Accuracy:  0.8545455\n",
      "epoch:  344  -  cost: 0.34649876  -MSE: 11.803353907265503  -Train Accuracy:  0.8545455\n",
      "epoch:  345  -  cost: 0.34691522  -MSE: 12.335665017154827  -Train Accuracy:  0.8545455\n",
      "epoch:  346  -  cost: 0.34595066  -MSE: 11.822004204789586  -Train Accuracy:  0.8545455\n",
      "epoch:  347  -  cost: 0.3465266  -MSE: 12.35005134025832  -Train Accuracy:  0.8545455\n",
      "epoch:  348  -  cost: 0.34523138  -MSE: 11.856399253706996  -Train Accuracy:  0.8545455\n",
      "epoch:  349  -  cost: 0.34564543  -MSE: 12.408256875537951  -Train Accuracy:  0.8545455\n",
      "epoch:  350  -  cost: 0.3446412  -MSE: 11.87295234982723  -Train Accuracy:  0.8545455\n",
      "epoch:  351  -  cost: 0.34527642  -MSE: 12.394448808419037  -Train Accuracy:  0.8545455\n",
      "epoch:  352  -  cost: 0.3440107  -MSE: 11.889051185562428  -Train Accuracy:  0.8545455\n",
      "epoch:  353  -  cost: 0.34435165  -MSE: 12.440954728945496  -Train Accuracy:  0.8545455\n",
      "epoch:  354  -  cost: 0.34285244  -MSE: 11.911125217559848  -Train Accuracy:  0.8545455\n",
      "epoch:  355  -  cost: 0.34348604  -MSE: 12.434763628140342  -Train Accuracy:  0.8545455\n",
      "epoch:  356  -  cost: 0.34215677  -MSE: 11.917436065529209  -Train Accuracy:  0.8545455\n",
      "epoch:  357  -  cost: 0.34243566  -MSE: 12.470539821837505  -Train Accuracy:  0.8545455\n",
      "epoch:  358  -  cost: 0.34151793  -MSE: 11.937302585057848  -Train Accuracy:  0.8545455\n",
      "epoch:  359  -  cost: 0.34216693  -MSE: 12.48315115732772  -Train Accuracy:  0.8545455\n",
      "epoch:  360  -  cost: 0.34068942  -MSE: 11.957152079928695  -Train Accuracy:  0.8545455\n",
      "epoch:  361  -  cost: 0.34118715  -MSE: 12.49542295239743  -Train Accuracy:  0.8545455\n",
      "epoch:  362  -  cost: 0.33992568  -MSE: 11.975474576254717  -Train Accuracy:  0.8545455\n",
      "epoch:  363  -  cost: 0.34017053  -MSE: 12.520464433423196  -Train Accuracy:  0.8545455\n",
      "epoch:  364  -  cost: 0.33899716  -MSE: 11.96912514232383  -Train Accuracy:  0.8545455\n",
      "epoch:  365  -  cost: 0.33944625  -MSE: 12.519490388663465  -Train Accuracy:  0.8545455\n",
      "epoch:  366  -  cost: 0.3385355  -MSE: 11.99014551844067  -Train Accuracy:  0.8545455\n",
      "epoch:  367  -  cost: 0.33863747  -MSE: 12.526781656563033  -Train Accuracy:  0.8545455\n",
      "epoch:  368  -  cost: 0.3374641  -MSE: 12.00486365880245  -Train Accuracy:  0.8545455\n",
      "epoch:  369  -  cost: 0.3377265  -MSE: 12.530554290321508  -Train Accuracy:  0.8545455\n",
      "epoch:  370  -  cost: 0.33670965  -MSE: 11.981403733015135  -Train Accuracy:  0.8545455\n",
      "epoch:  371  -  cost: 0.3365221  -MSE: 12.52493199296671  -Train Accuracy:  0.8545455\n",
      "epoch:  372  -  cost: 0.3354725  -MSE: 11.99766538647555  -Train Accuracy:  0.8545455\n",
      "epoch:  373  -  cost: 0.3355995  -MSE: 12.514653052583313  -Train Accuracy:  0.8545455\n",
      "epoch:  374  -  cost: 0.33453557  -MSE: 12.013639459882954  -Train Accuracy:  0.8606061\n",
      "epoch:  375  -  cost: 0.3342173  -MSE: 12.5333716195393  -Train Accuracy:  0.8545455\n",
      "epoch:  376  -  cost: 0.3332573  -MSE: 12.002548596546886  -Train Accuracy:  0.8666667\n",
      "epoch:  377  -  cost: 0.33337235  -MSE: 12.537759519923819  -Train Accuracy:  0.8545455\n",
      "epoch:  378  -  cost: 0.33272758  -MSE: 12.018470335131594  -Train Accuracy:  0.8606061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  379  -  cost: 0.33249667  -MSE: 12.544819311750281  -Train Accuracy:  0.8545455\n",
      "epoch:  380  -  cost: 0.33076912  -MSE: 12.035042262822682  -Train Accuracy:  0.8666667\n",
      "epoch:  381  -  cost: 0.3303365  -MSE: 12.536743665219277  -Train Accuracy:  0.8545455\n",
      "epoch:  382  -  cost: 0.32867828  -MSE: 12.029747127052753  -Train Accuracy:  0.8666667\n",
      "epoch:  383  -  cost: 0.32848322  -MSE: 12.502220926370992  -Train Accuracy:  0.8606061\n",
      "epoch:  384  -  cost: 0.32716507  -MSE: 12.037672783297126  -Train Accuracy:  0.8727273\n",
      "epoch:  385  -  cost: 0.32710594  -MSE: 12.523510784531931  -Train Accuracy:  0.8606061\n",
      "epoch:  386  -  cost: 0.32577798  -MSE: 12.051615284513762  -Train Accuracy:  0.8666667\n",
      "epoch:  387  -  cost: 0.32557786  -MSE: 12.51278958210086  -Train Accuracy:  0.8666667\n",
      "epoch:  388  -  cost: 0.3245955  -MSE: 12.044869129334652  -Train Accuracy:  0.8666667\n",
      "epoch:  389  -  cost: 0.324395  -MSE: 12.504470976521898  -Train Accuracy:  0.8666667\n",
      "epoch:  390  -  cost: 0.3230253  -MSE: 12.068881286641636  -Train Accuracy:  0.8727273\n",
      "epoch:  391  -  cost: 0.32267153  -MSE: 12.520640135101003  -Train Accuracy:  0.8606061\n",
      "epoch:  392  -  cost: 0.32150808  -MSE: 12.078181217529206  -Train Accuracy:  0.8727273\n",
      "epoch:  393  -  cost: 0.32131916  -MSE: 12.489834435814451  -Train Accuracy:  0.8606061\n",
      "epoch:  394  -  cost: 0.32035154  -MSE: 12.104837844621928  -Train Accuracy:  0.8727273\n",
      "epoch:  395  -  cost: 0.32001805  -MSE: 12.52381243267981  -Train Accuracy:  0.8727273\n",
      "epoch:  396  -  cost: 0.3198315  -MSE: 12.099950609896403  -Train Accuracy:  0.8727273\n",
      "epoch:  397  -  cost: 0.31963682  -MSE: 12.549545174569154  -Train Accuracy:  0.8727273\n",
      "epoch:  398  -  cost: 0.31879294  -MSE: 12.133264837093062  -Train Accuracy:  0.8727273\n",
      "epoch:  399  -  cost: 0.31845963  -MSE: 12.547480949121399  -Train Accuracy:  0.8727273\n",
      "epoch:  400  -  cost: 0.31769747  -MSE: 12.145085511604682  -Train Accuracy:  0.8727273\n",
      "epoch:  401  -  cost: 0.31720653  -MSE: 12.537540452723132  -Train Accuracy:  0.8727273\n",
      "epoch:  402  -  cost: 0.31630105  -MSE: 12.129072561106536  -Train Accuracy:  0.8727273\n",
      "epoch:  403  -  cost: 0.31597933  -MSE: 12.532881773840112  -Train Accuracy:  0.8727273\n",
      "epoch:  404  -  cost: 0.3151985  -MSE: 12.119793704705295  -Train Accuracy:  0.8727273\n",
      "epoch:  405  -  cost: 0.3149159  -MSE: 12.51951723244018  -Train Accuracy:  0.8666667\n",
      "epoch:  406  -  cost: 0.31419244  -MSE: 12.134259937343973  -Train Accuracy:  0.8727273\n",
      "epoch:  407  -  cost: 0.31408882  -MSE: 12.541931646785216  -Train Accuracy:  0.8666667\n",
      "epoch:  408  -  cost: 0.31329352  -MSE: 12.1214101568182  -Train Accuracy:  0.8727273\n",
      "epoch:  409  -  cost: 0.31321883  -MSE: 12.529644320836415  -Train Accuracy:  0.8666667\n",
      "epoch:  410  -  cost: 0.3124316  -MSE: 12.117074535515108  -Train Accuracy:  0.8727273\n",
      "epoch:  411  -  cost: 0.31252047  -MSE: 12.50538306164643  -Train Accuracy:  0.8666667\n",
      "epoch:  412  -  cost: 0.3120369  -MSE: 12.137384804291518  -Train Accuracy:  0.8727273\n",
      "epoch:  413  -  cost: 0.31231457  -MSE: 12.548295569257064  -Train Accuracy:  0.8666667\n",
      "epoch:  414  -  cost: 0.31270888  -MSE: 12.130831787706807  -Train Accuracy:  0.8727273\n",
      "epoch:  415  -  cost: 0.31269947  -MSE: 12.59268078908345  -Train Accuracy:  0.8727273\n",
      "epoch:  416  -  cost: 0.31321084  -MSE: 12.145705999962834  -Train Accuracy:  0.8787879\n",
      "epoch:  417  -  cost: 0.3131801  -MSE: 12.632749983943736  -Train Accuracy:  0.8727273\n",
      "epoch:  418  -  cost: 0.31284046  -MSE: 12.15841440683708  -Train Accuracy:  0.8787879\n",
      "epoch:  419  -  cost: 0.3128095  -MSE: 12.652825472635183  -Train Accuracy:  0.8787879\n",
      "epoch:  420  -  cost: 0.312544  -MSE: 12.153163237095844  -Train Accuracy:  0.8848485\n",
      "epoch:  421  -  cost: 0.3127072  -MSE: 12.665118152519463  -Train Accuracy:  0.8787879\n",
      "epoch:  422  -  cost: 0.3119851  -MSE: 12.186916406105706  -Train Accuracy:  0.8848485\n",
      "epoch:  423  -  cost: 0.31197023  -MSE: 12.652192318343076  -Train Accuracy:  0.8787879\n",
      "epoch:  424  -  cost: 0.31154993  -MSE: 12.158517755228983  -Train Accuracy:  0.8848485\n",
      "epoch:  425  -  cost: 0.3115251  -MSE: 12.65240745659178  -Train Accuracy:  0.8787879\n",
      "epoch:  426  -  cost: 0.3119083  -MSE: 12.13292866067375  -Train Accuracy:  0.8787879\n",
      "epoch:  427  -  cost: 0.3126365  -MSE: 12.66385555497093  -Train Accuracy:  0.8787879\n",
      "epoch:  428  -  cost: 0.31250882  -MSE: 12.143027248905097  -Train Accuracy:  0.8727273\n",
      "epoch:  429  -  cost: 0.31287682  -MSE: 12.684224840143836  -Train Accuracy:  0.8787879\n",
      "epoch:  430  -  cost: 0.31297085  -MSE: 12.114290850845927  -Train Accuracy:  0.8727273\n",
      "epoch:  431  -  cost: 0.3138258  -MSE: 12.685570675580632  -Train Accuracy:  0.8787879\n",
      "epoch:  432  -  cost: 0.31368342  -MSE: 12.103306922215157  -Train Accuracy:  0.8787879\n",
      "epoch:  433  -  cost: 0.31387657  -MSE: 12.721825358000777  -Train Accuracy:  0.8787879\n",
      "epoch:  434  -  cost: 0.31238523  -MSE: 12.13447989083754  -Train Accuracy:  0.8727273\n",
      "epoch:  435  -  cost: 0.31287336  -MSE: 12.74128704231243  -Train Accuracy:  0.8787879\n",
      "epoch:  436  -  cost: 0.31262928  -MSE: 12.154333749355695  -Train Accuracy:  0.8787879\n",
      "epoch:  437  -  cost: 0.31305566  -MSE: 12.753109657712164  -Train Accuracy:  0.8848485\n",
      "epoch:  438  -  cost: 0.31275803  -MSE: 12.130076741596621  -Train Accuracy:  0.8787879\n",
      "epoch:  439  -  cost: 0.31314468  -MSE: 12.762363944933643  -Train Accuracy:  0.8848485\n",
      "epoch:  440  -  cost: 0.31144854  -MSE: 12.165596890465375  -Train Accuracy:  0.8787879\n",
      "epoch:  441  -  cost: 0.31130514  -MSE: 12.783198683459764  -Train Accuracy:  0.8848485\n",
      "epoch:  442  -  cost: 0.31006476  -MSE: 12.175977460837549  -Train Accuracy:  0.8787879\n",
      "epoch:  443  -  cost: 0.30988747  -MSE: 12.780985437092127  -Train Accuracy:  0.8848485\n",
      "epoch:  444  -  cost: 0.30854627  -MSE: 12.227252163786895  -Train Accuracy:  0.8727273\n",
      "epoch:  445  -  cost: 0.30858162  -MSE: 12.783689245683206  -Train Accuracy:  0.8848485\n",
      "epoch:  446  -  cost: 0.30753002  -MSE: 12.205966208334129  -Train Accuracy:  0.8727273\n",
      "epoch:  447  -  cost: 0.3073234  -MSE: 12.801212428655203  -Train Accuracy:  0.8787879\n",
      "epoch:  448  -  cost: 0.30624905  -MSE: 12.235963842730314  -Train Accuracy:  0.8727273\n",
      "epoch:  449  -  cost: 0.3060527  -MSE: 12.81111768228418  -Train Accuracy:  0.8787879\n",
      "epoch:  450  -  cost: 0.30487663  -MSE: 12.263850922721282  -Train Accuracy:  0.8787879\n",
      "epoch:  451  -  cost: 0.3047266  -MSE: 12.790340531325084  -Train Accuracy:  0.8787879\n",
      "epoch:  452  -  cost: 0.30373374  -MSE: 12.26128004144691  -Train Accuracy:  0.8787879\n",
      "epoch:  453  -  cost: 0.30354434  -MSE: 12.830065995615708  -Train Accuracy:  0.8787879\n",
      "epoch:  454  -  cost: 0.3025741  -MSE: 12.306669037966193  -Train Accuracy:  0.8787879\n",
      "epoch:  455  -  cost: 0.3025023  -MSE: 12.831856806848517  -Train Accuracy:  0.8787879\n",
      "epoch:  456  -  cost: 0.3014342  -MSE: 12.343230231696019  -Train Accuracy:  0.8787879\n",
      "epoch:  457  -  cost: 0.30092236  -MSE: 12.852719480183561  -Train Accuracy:  0.8848485\n",
      "epoch:  458  -  cost: 0.2999724  -MSE: 12.397955076870485  -Train Accuracy:  0.8848485\n",
      "epoch:  459  -  cost: 0.2996872  -MSE: 12.896428007274478  -Train Accuracy:  0.8848485\n",
      "epoch:  460  -  cost: 0.2990115  -MSE: 12.441393748324563  -Train Accuracy:  0.8848485\n",
      "epoch:  461  -  cost: 0.29882362  -MSE: 12.930404867541867  -Train Accuracy:  0.8848485\n",
      "epoch:  462  -  cost: 0.29838267  -MSE: 12.423339855285565  -Train Accuracy:  0.8848485\n",
      "epoch:  463  -  cost: 0.2986504  -MSE: 12.951731981702546  -Train Accuracy:  0.8909091\n",
      "epoch:  464  -  cost: 0.2977377  -MSE: 12.487549788921363  -Train Accuracy:  0.8848485\n",
      "epoch:  465  -  cost: 0.29757902  -MSE: 12.980738836660256  -Train Accuracy:  0.8848485\n",
      "epoch:  466  -  cost: 0.29698434  -MSE: 12.48999389204859  -Train Accuracy:  0.8848485\n",
      "epoch:  467  -  cost: 0.29694661  -MSE: 12.998070036965263  -Train Accuracy:  0.8909091\n",
      "epoch:  468  -  cost: 0.29593158  -MSE: 12.537969776672583  -Train Accuracy:  0.8848485\n",
      "epoch:  469  -  cost: 0.29602984  -MSE: 13.02822556213693  -Train Accuracy:  0.8909091\n",
      "epoch:  470  -  cost: 0.29568207  -MSE: 12.528199800370942  -Train Accuracy:  0.8848485\n",
      "epoch:  471  -  cost: 0.29588014  -MSE: 13.05578538852313  -Train Accuracy:  0.8909091\n",
      "epoch:  472  -  cost: 0.2951185  -MSE: 12.569703919484109  -Train Accuracy:  0.8848485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  473  -  cost: 0.29531217  -MSE: 13.084980867614377  -Train Accuracy:  0.8909091\n",
      "epoch:  474  -  cost: 0.29451358  -MSE: 12.591851615268396  -Train Accuracy:  0.8848485\n",
      "epoch:  475  -  cost: 0.29465374  -MSE: 13.093420310852439  -Train Accuracy:  0.8909091\n",
      "epoch:  476  -  cost: 0.2941115  -MSE: 12.601628825820317  -Train Accuracy:  0.8848485\n",
      "epoch:  477  -  cost: 0.29425478  -MSE: 13.148875757948097  -Train Accuracy:  0.8909091\n",
      "epoch:  478  -  cost: 0.29341948  -MSE: 12.661834177471126  -Train Accuracy:  0.8848485\n",
      "epoch:  479  -  cost: 0.2936506  -MSE: 13.17251752507722  -Train Accuracy:  0.8909091\n",
      "epoch:  480  -  cost: 0.29284322  -MSE: 12.679374311496039  -Train Accuracy:  0.8848485\n",
      "epoch:  481  -  cost: 0.29309517  -MSE: 13.208762940526215  -Train Accuracy:  0.8909091\n",
      "epoch:  482  -  cost: 0.29237774  -MSE: 12.713513641472408  -Train Accuracy:  0.8848485\n",
      "epoch:  483  -  cost: 0.29257393  -MSE: 13.248689761620549  -Train Accuracy:  0.8909091\n",
      "epoch:  484  -  cost: 0.29201388  -MSE: 12.708735276393368  -Train Accuracy:  0.8848485\n",
      "epoch:  485  -  cost: 0.29227874  -MSE: 13.248237646789292  -Train Accuracy:  0.8909091\n",
      "epoch:  486  -  cost: 0.29149437  -MSE: 12.759028239816747  -Train Accuracy:  0.8848485\n",
      "epoch:  487  -  cost: 0.29187742  -MSE: 13.305587237380163  -Train Accuracy:  0.8909091\n",
      "epoch:  488  -  cost: 0.29095793  -MSE: 12.790852442665866  -Train Accuracy:  0.8848485\n",
      "epoch:  489  -  cost: 0.29126495  -MSE: 13.338034403182357  -Train Accuracy:  0.8909091\n",
      "epoch:  490  -  cost: 0.2907206  -MSE: 12.786324868273208  -Train Accuracy:  0.8848485\n",
      "epoch:  491  -  cost: 0.29113767  -MSE: 13.342033564244579  -Train Accuracy:  0.8909091\n",
      "epoch:  492  -  cost: 0.29045084  -MSE: 12.829795240564755  -Train Accuracy:  0.8909091\n",
      "epoch:  493  -  cost: 0.2909059  -MSE: 13.38813465262328  -Train Accuracy:  0.8909091\n",
      "epoch:  494  -  cost: 0.2906474  -MSE: 12.813567224595598  -Train Accuracy:  0.8848485\n",
      "epoch:  495  -  cost: 0.29124734  -MSE: 13.414981138545816  -Train Accuracy:  0.8909091\n",
      "epoch:  496  -  cost: 0.29056928  -MSE: 12.839926865062099  -Train Accuracy:  0.8848485\n",
      "epoch:  497  -  cost: 0.29083574  -MSE: 13.447663372352313  -Train Accuracy:  0.8909091\n",
      "epoch:  498  -  cost: 0.29003  -MSE: 12.867471745754065  -Train Accuracy:  0.8848485\n",
      "epoch:  499  -  cost: 0.2907298  -MSE: 13.486537362260348  -Train Accuracy:  0.8909091\n",
      "epoch:  500  -  cost: 0.29003602  -MSE: 12.848465000297189  -Train Accuracy:  0.8848485\n",
      "epoch:  501  -  cost: 0.29087508  -MSE: 13.48805963813655  -Train Accuracy:  0.8969697\n",
      "epoch:  502  -  cost: 0.2899945  -MSE: 12.925223586178948  -Train Accuracy:  0.8848485\n",
      "epoch:  503  -  cost: 0.29079813  -MSE: 13.565405220570034  -Train Accuracy:  0.8969697\n",
      "epoch:  504  -  cost: 0.29040307  -MSE: 12.919037594967724  -Train Accuracy:  0.8848485\n",
      "epoch:  505  -  cost: 0.29124776  -MSE: 13.578402577342935  -Train Accuracy:  0.8969697\n",
      "epoch:  506  -  cost: 0.2906407  -MSE: 12.921895607716957  -Train Accuracy:  0.8848485\n",
      "epoch:  507  -  cost: 0.29216382  -MSE: 13.637246538649439  -Train Accuracy:  0.8969697\n",
      "epoch:  508  -  cost: 0.29226598  -MSE: 12.970022056205897  -Train Accuracy:  0.8848485\n",
      "epoch:  509  -  cost: 0.29373217  -MSE: 13.693366426681772  -Train Accuracy:  0.8969697\n",
      "epoch:  510  -  cost: 0.29400805  -MSE: 12.949811166650264  -Train Accuracy:  0.8848485\n",
      "epoch:  511  -  cost: 0.29593736  -MSE: 13.750776201848701  -Train Accuracy:  0.8969697\n",
      "epoch:  512  -  cost: 0.29608795  -MSE: 12.968269744057547  -Train Accuracy:  0.8848485\n",
      "epoch:  513  -  cost: 0.29761118  -MSE: 13.813026811196297  -Train Accuracy:  0.8909091\n",
      "epoch:  514  -  cost: 0.2955597  -MSE: 13.00079264343474  -Train Accuracy:  0.8848485\n",
      "epoch:  515  -  cost: 0.2970097  -MSE: 13.823450183384466  -Train Accuracy:  0.8909091\n",
      "epoch:  516  -  cost: 0.29659113  -MSE: 12.981228597971695  -Train Accuracy:  0.8848485\n",
      "epoch:  517  -  cost: 0.2976749  -MSE: 13.839641626720988  -Train Accuracy:  0.8909091\n",
      "epoch:  518  -  cost: 0.29553816  -MSE: 12.969165398735129  -Train Accuracy:  0.8909091\n",
      "epoch:  519  -  cost: 0.29635605  -MSE: 13.8259942349085  -Train Accuracy:  0.8909091\n",
      "epoch:  520  -  cost: 0.29387134  -MSE: 12.990806910254978  -Train Accuracy:  0.8909091\n",
      "epoch:  521  -  cost: 0.294588  -MSE: 13.823028456994424  -Train Accuracy:  0.8909091\n",
      "epoch:  522  -  cost: 0.29248494  -MSE: 12.993554091180808  -Train Accuracy:  0.8909091\n",
      "epoch:  523  -  cost: 0.2928773  -MSE: 13.81019143673962  -Train Accuracy:  0.8969697\n",
      "epoch:  524  -  cost: 0.2907862  -MSE: 13.003354096829417  -Train Accuracy:  0.8909091\n",
      "epoch:  525  -  cost: 0.29120117  -MSE: 13.805402119711278  -Train Accuracy:  0.8969697\n",
      "epoch:  526  -  cost: 0.289061  -MSE: 13.02348508061286  -Train Accuracy:  0.8909091\n",
      "epoch:  527  -  cost: 0.28906736  -MSE: 13.801512723452381  -Train Accuracy:  0.8969697\n",
      "epoch:  528  -  cost: 0.28687733  -MSE: 13.047154734160559  -Train Accuracy:  0.8848485\n",
      "epoch:  529  -  cost: 0.28698543  -MSE: 13.810698327877379  -Train Accuracy:  0.8969697\n",
      "epoch:  530  -  cost: 0.28501102  -MSE: 13.0546851637022  -Train Accuracy:  0.8848485\n",
      "epoch:  531  -  cost: 0.28491056  -MSE: 13.797364600112857  -Train Accuracy:  0.8969697\n",
      "epoch:  532  -  cost: 0.2816774  -MSE: 13.09267818524755  -Train Accuracy:  0.8848485\n",
      "epoch:  533  -  cost: 0.28161272  -MSE: 13.776096948378413  -Train Accuracy:  0.8969697\n",
      "epoch:  534  -  cost: 0.2793462  -MSE: 13.0926865457912  -Train Accuracy:  0.8848485\n",
      "epoch:  535  -  cost: 0.2787845  -MSE: 13.784395794975207  -Train Accuracy:  0.8969697\n",
      "epoch:  536  -  cost: 0.27654186  -MSE: 13.159148459860656  -Train Accuracy:  0.8969697\n",
      "epoch:  537  -  cost: 0.27664107  -MSE: 13.799266028318751  -Train Accuracy:  0.8969697\n",
      "epoch:  538  -  cost: 0.27488062  -MSE: 13.160237595419469  -Train Accuracy:  0.90909094\n",
      "epoch:  539  -  cost: 0.27519846  -MSE: 13.78523462513746  -Train Accuracy:  0.8969697\n",
      "epoch:  540  -  cost: 0.27429497  -MSE: 13.222829826458705  -Train Accuracy:  0.90909094\n",
      "epoch:  541  -  cost: 0.27444667  -MSE: 13.837361689996618  -Train Accuracy:  0.8969697\n",
      "epoch:  542  -  cost: 0.27377683  -MSE: 13.235022802861895  -Train Accuracy:  0.90909094\n",
      "epoch:  543  -  cost: 0.27384594  -MSE: 13.847140186938098  -Train Accuracy:  0.8969697\n",
      "epoch:  544  -  cost: 0.2731966  -MSE: 13.242681921771826  -Train Accuracy:  0.91515154\n",
      "epoch:  545  -  cost: 0.27373365  -MSE: 13.862954348001297  -Train Accuracy:  0.8969697\n",
      "epoch:  546  -  cost: 0.27298847  -MSE: 13.291231465467723  -Train Accuracy:  0.91515154\n",
      "epoch:  547  -  cost: 0.2736885  -MSE: 13.923992015888643  -Train Accuracy:  0.8969697\n",
      "epoch:  548  -  cost: 0.2732524  -MSE: 13.291322345959987  -Train Accuracy:  0.90909094\n",
      "epoch:  549  -  cost: 0.2737048  -MSE: 13.945899923601306  -Train Accuracy:  0.8969697\n",
      "epoch:  550  -  cost: 0.27298936  -MSE: 13.307114695407144  -Train Accuracy:  0.9030303\n",
      "epoch:  551  -  cost: 0.27392015  -MSE: 13.979614668274161  -Train Accuracy:  0.8969697\n",
      "epoch:  552  -  cost: 0.2730004  -MSE: 13.315985452226172  -Train Accuracy:  0.9030303\n",
      "epoch:  553  -  cost: 0.27370098  -MSE: 13.995995749890897  -Train Accuracy:  0.8969697\n",
      "epoch:  554  -  cost: 0.2724464  -MSE: 13.350383274938011  -Train Accuracy:  0.9030303\n",
      "epoch:  555  -  cost: 0.27341756  -MSE: 14.053474007014406  -Train Accuracy:  0.8969697\n",
      "epoch:  556  -  cost: 0.2726246  -MSE: 13.369469424556506  -Train Accuracy:  0.9030303\n",
      "epoch:  557  -  cost: 0.27337903  -MSE: 14.092233733248431  -Train Accuracy:  0.8969697\n",
      "epoch:  558  -  cost: 0.27249226  -MSE: 13.385577622004197  -Train Accuracy:  0.9030303\n",
      "epoch:  559  -  cost: 0.2730731  -MSE: 14.133331643269575  -Train Accuracy:  0.8969697\n",
      "epoch:  560  -  cost: 0.27178743  -MSE: 13.451220409896601  -Train Accuracy:  0.9030303\n",
      "epoch:  561  -  cost: 0.27293557  -MSE: 14.18081543250999  -Train Accuracy:  0.8969697\n",
      "epoch:  562  -  cost: 0.2719577  -MSE: 13.455564177395624  -Train Accuracy:  0.8969697\n",
      "epoch:  563  -  cost: 0.27276975  -MSE: 14.198567180868773  -Train Accuracy:  0.8969697\n",
      "epoch:  564  -  cost: 0.27140424  -MSE: 13.49468775530932  -Train Accuracy:  0.8969697\n",
      "epoch:  565  -  cost: 0.27281678  -MSE: 14.241040429895442  -Train Accuracy:  0.8969697\n",
      "epoch:  566  -  cost: 0.27156883  -MSE: 13.488181143615597  -Train Accuracy:  0.8969697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  567  -  cost: 0.27264738  -MSE: 14.251783527428586  -Train Accuracy:  0.8969697\n",
      "epoch:  568  -  cost: 0.27118486  -MSE: 13.498100229016288  -Train Accuracy:  0.8969697\n",
      "epoch:  569  -  cost: 0.2723383  -MSE: 14.270787500273178  -Train Accuracy:  0.8969697\n",
      "epoch:  570  -  cost: 0.27061328  -MSE: 13.539320995314077  -Train Accuracy:  0.8969697\n",
      "epoch:  571  -  cost: 0.27137092  -MSE: 14.316398612028674  -Train Accuracy:  0.8969697\n",
      "epoch:  572  -  cost: 0.27020007  -MSE: 13.56845143090895  -Train Accuracy:  0.8969697\n",
      "epoch:  573  -  cost: 0.2714097  -MSE: 14.348192063463355  -Train Accuracy:  0.8969697\n",
      "epoch:  574  -  cost: 0.27005032  -MSE: 13.583676850449566  -Train Accuracy:  0.8969697\n",
      "epoch:  575  -  cost: 0.2709956  -MSE: 14.384077218771207  -Train Accuracy:  0.8969697\n",
      "epoch:  576  -  cost: 0.26913643  -MSE: 13.613039725089855  -Train Accuracy:  0.8969697\n",
      "epoch:  577  -  cost: 0.2697321  -MSE: 14.383840744725887  -Train Accuracy:  0.8969697\n",
      "epoch:  578  -  cost: 0.26837334  -MSE: 13.613745051873252  -Train Accuracy:  0.8969697\n",
      "epoch:  579  -  cost: 0.26884234  -MSE: 14.405158862422606  -Train Accuracy:  0.8969697\n",
      "epoch:  580  -  cost: 0.26718637  -MSE: 13.665215677765461  -Train Accuracy:  0.8969697\n",
      "epoch:  581  -  cost: 0.26796728  -MSE: 14.418955894840037  -Train Accuracy:  0.8969697\n",
      "epoch:  582  -  cost: 0.26659226  -MSE: 13.651915412422222  -Train Accuracy:  0.8969697\n",
      "epoch:  583  -  cost: 0.2674904  -MSE: 14.418220918340188  -Train Accuracy:  0.8969697\n",
      "epoch:  584  -  cost: 0.2660562  -MSE: 13.645266426585309  -Train Accuracy:  0.8969697\n",
      "epoch:  585  -  cost: 0.26634967  -MSE: 14.421446385452203  -Train Accuracy:  0.8969697\n",
      "epoch:  586  -  cost: 0.2646754  -MSE: 13.685355431990573  -Train Accuracy:  0.9030303\n",
      "epoch:  587  -  cost: 0.26527175  -MSE: 14.42348292870045  -Train Accuracy:  0.8969697\n",
      "epoch:  588  -  cost: 0.2639208  -MSE: 13.659726624490483  -Train Accuracy:  0.9030303\n",
      "epoch:  589  -  cost: 0.26430392  -MSE: 14.38772037612152  -Train Accuracy:  0.8969697\n",
      "epoch:  590  -  cost: 0.2617358  -MSE: 13.646752171379116  -Train Accuracy:  0.90909094\n",
      "epoch:  591  -  cost: 0.26189864  -MSE: 14.39620698973491  -Train Accuracy:  0.8969697\n",
      "epoch:  592  -  cost: 0.25992894  -MSE: 13.671495116214953  -Train Accuracy:  0.91515154\n",
      "epoch:  593  -  cost: 0.25996536  -MSE: 14.358387181760092  -Train Accuracy:  0.8969697\n",
      "epoch:  594  -  cost: 0.25793862  -MSE: 13.6688661266467  -Train Accuracy:  0.91515154\n",
      "epoch:  595  -  cost: 0.25752705  -MSE: 14.331273866322906  -Train Accuracy:  0.9030303\n",
      "epoch:  596  -  cost: 0.2560882  -MSE: 13.657174626773852  -Train Accuracy:  0.91515154\n",
      "epoch:  597  -  cost: 0.25609738  -MSE: 14.283099144729054  -Train Accuracy:  0.90909094\n",
      "epoch:  598  -  cost: 0.25425005  -MSE: 13.643037422280573  -Train Accuracy:  0.91515154\n",
      "epoch:  599  -  cost: 0.2541764  -MSE: 14.244474524466195  -Train Accuracy:  0.91515154\n",
      "epoch:  600  -  cost: 0.2529155  -MSE: 13.617708117594654  -Train Accuracy:  0.91515154\n",
      "epoch:  601  -  cost: 0.25281453  -MSE: 14.211086764573722  -Train Accuracy:  0.91515154\n",
      "epoch:  602  -  cost: 0.25140524  -MSE: 13.632334291986673  -Train Accuracy:  0.91515154\n",
      "epoch:  603  -  cost: 0.2515916  -MSE: 14.178697946835227  -Train Accuracy:  0.91515154\n",
      "epoch:  604  -  cost: 0.25046793  -MSE: 13.586549628859492  -Train Accuracy:  0.91515154\n",
      "epoch:  605  -  cost: 0.2503217  -MSE: 14.192583785801375  -Train Accuracy:  0.92121214\n",
      "epoch:  606  -  cost: 0.24922855  -MSE: 13.623177176478153  -Train Accuracy:  0.91515154\n",
      "epoch:  607  -  cost: 0.24884109  -MSE: 14.166432602679063  -Train Accuracy:  0.92121214\n",
      "epoch:  608  -  cost: 0.24791035  -MSE: 13.606423253460976  -Train Accuracy:  0.92121214\n",
      "epoch:  609  -  cost: 0.2475945  -MSE: 14.133202823810155  -Train Accuracy:  0.93333334\n",
      "epoch:  610  -  cost: 0.24634168  -MSE: 13.612432655593445  -Train Accuracy:  0.92121214\n",
      "epoch:  611  -  cost: 0.24609928  -MSE: 14.132006171114629  -Train Accuracy:  0.92727274\n",
      "epoch:  612  -  cost: 0.2453031  -MSE: 13.614559010265049  -Train Accuracy:  0.92121214\n",
      "epoch:  613  -  cost: 0.2447934  -MSE: 14.115852534504116  -Train Accuracy:  0.92727274\n",
      "epoch:  614  -  cost: 0.24407193  -MSE: 13.607484645888722  -Train Accuracy:  0.92121214\n",
      "epoch:  615  -  cost: 0.24357417  -MSE: 14.12252429438017  -Train Accuracy:  0.92727274\n",
      "epoch:  616  -  cost: 0.2423245  -MSE: 13.6538175179092  -Train Accuracy:  0.92727274\n",
      "epoch:  617  -  cost: 0.24188311  -MSE: 14.098011667548597  -Train Accuracy:  0.93333334\n",
      "epoch:  618  -  cost: 0.24137866  -MSE: 13.64199381093975  -Train Accuracy:  0.92727274\n",
      "epoch:  619  -  cost: 0.2408958  -MSE: 14.110067547458438  -Train Accuracy:  0.93333334\n",
      "epoch:  620  -  cost: 0.23989102  -MSE: 13.664192894564579  -Train Accuracy:  0.92727274\n",
      "epoch:  621  -  cost: 0.23949379  -MSE: 14.110835522799583  -Train Accuracy:  0.93939394\n",
      "epoch:  622  -  cost: 0.2390602  -MSE: 13.707268808340988  -Train Accuracy:  0.92727274\n",
      "epoch:  623  -  cost: 0.23857903  -MSE: 14.136836974099358  -Train Accuracy:  0.93939394\n",
      "epoch:  624  -  cost: 0.23833154  -MSE: 13.710391971051292  -Train Accuracy:  0.92727274\n",
      "epoch:  625  -  cost: 0.23796299  -MSE: 14.136437787111179  -Train Accuracy:  0.93939394\n",
      "epoch:  626  -  cost: 0.23749945  -MSE: 13.764401285001751  -Train Accuracy:  0.92727274\n",
      "epoch:  627  -  cost: 0.23717733  -MSE: 14.184401210625419  -Train Accuracy:  0.93939394\n",
      "epoch:  628  -  cost: 0.23689136  -MSE: 13.784172335831716  -Train Accuracy:  0.93333334\n",
      "epoch:  629  -  cost: 0.23654163  -MSE: 14.20034917520195  -Train Accuracy:  0.93939394\n",
      "epoch:  630  -  cost: 0.23633383  -MSE: 13.80641392935419  -Train Accuracy:  0.93333334\n",
      "epoch:  631  -  cost: 0.23620652  -MSE: 14.2245746549192  -Train Accuracy:  0.93939394\n",
      "epoch:  632  -  cost: 0.23565665  -MSE: 13.859010333851089  -Train Accuracy:  0.93333334\n",
      "epoch:  633  -  cost: 0.23552896  -MSE: 14.239051962146128  -Train Accuracy:  0.93939394\n",
      "epoch:  634  -  cost: 0.2355324  -MSE: 13.873722774941571  -Train Accuracy:  0.93939394\n",
      "epoch:  635  -  cost: 0.23522656  -MSE: 14.301400650868956  -Train Accuracy:  0.93939394\n",
      "epoch:  636  -  cost: 0.2354218  -MSE: 13.915187203068015  -Train Accuracy:  0.93939394\n",
      "epoch:  637  -  cost: 0.23529226  -MSE: 14.32306432841883  -Train Accuracy:  0.93333334\n",
      "epoch:  638  -  cost: 0.23538674  -MSE: 13.93574721286778  -Train Accuracy:  0.92727274\n",
      "epoch:  639  -  cost: 0.23547602  -MSE: 14.417493084171037  -Train Accuracy:  0.93333334\n",
      "epoch:  640  -  cost: 0.2356915  -MSE: 13.972713572914396  -Train Accuracy:  0.92727274\n",
      "epoch:  641  -  cost: 0.23594761  -MSE: 14.462202943075651  -Train Accuracy:  0.93333334\n",
      "epoch:  642  -  cost: 0.23587535  -MSE: 14.011350709930888  -Train Accuracy:  0.92121214\n",
      "epoch:  643  -  cost: 0.23620827  -MSE: 14.52888575519341  -Train Accuracy:  0.93333334\n",
      "epoch:  644  -  cost: 0.23605455  -MSE: 14.029361849827264  -Train Accuracy:  0.92121214\n",
      "epoch:  645  -  cost: 0.23647954  -MSE: 14.586577213738405  -Train Accuracy:  0.93333334\n",
      "epoch:  646  -  cost: 0.23642714  -MSE: 14.06284065789248  -Train Accuracy:  0.92121214\n",
      "epoch:  647  -  cost: 0.23682378  -MSE: 14.635811691230561  -Train Accuracy:  0.93333334\n",
      "epoch:  648  -  cost: 0.23635557  -MSE: 14.090310648795528  -Train Accuracy:  0.92121214\n",
      "epoch:  649  -  cost: 0.23691241  -MSE: 14.680936653137959  -Train Accuracy:  0.93333334\n",
      "epoch:  650  -  cost: 0.23631883  -MSE: 14.13594382571286  -Train Accuracy:  0.92121214\n",
      "epoch:  651  -  cost: 0.23679733  -MSE: 14.741605316780936  -Train Accuracy:  0.93333334\n",
      "epoch:  652  -  cost: 0.23614164  -MSE: 14.158879576883097  -Train Accuracy:  0.92121214\n",
      "epoch:  653  -  cost: 0.23651074  -MSE: 14.796773800302747  -Train Accuracy:  0.93333334\n",
      "epoch:  654  -  cost: 0.23612276  -MSE: 14.192451695268975  -Train Accuracy:  0.92121214\n",
      "epoch:  655  -  cost: 0.23675546  -MSE: 14.840168833172592  -Train Accuracy:  0.93333334\n",
      "epoch:  656  -  cost: 0.23590624  -MSE: 14.247962286846324  -Train Accuracy:  0.92727274\n",
      "epoch:  657  -  cost: 0.23656043  -MSE: 14.91138371728229  -Train Accuracy:  0.93333334\n",
      "epoch:  658  -  cost: 0.23571894  -MSE: 14.287159046891421  -Train Accuracy:  0.92121214\n",
      "epoch:  659  -  cost: 0.23624764  -MSE: 14.97013422273463  -Train Accuracy:  0.93333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  660  -  cost: 0.23549539  -MSE: 14.292213113948916  -Train Accuracy:  0.92121214\n",
      "epoch:  661  -  cost: 0.23628612  -MSE: 15.016239996924075  -Train Accuracy:  0.93333334\n",
      "epoch:  662  -  cost: 0.23497483  -MSE: 14.365049887468471  -Train Accuracy:  0.92121214\n",
      "epoch:  663  -  cost: 0.23533009  -MSE: 15.044933107624356  -Train Accuracy:  0.93333334\n",
      "epoch:  664  -  cost: 0.23397617  -MSE: 14.39949135163922  -Train Accuracy:  0.92121214\n",
      "epoch:  665  -  cost: 0.23439874  -MSE: 15.081510007826802  -Train Accuracy:  0.93333334\n",
      "epoch:  666  -  cost: 0.23322389  -MSE: 14.403521899541968  -Train Accuracy:  0.92121214\n",
      "epoch:  667  -  cost: 0.2337459  -MSE: 15.16075413024661  -Train Accuracy:  0.93333334\n",
      "epoch:  668  -  cost: 0.23252727  -MSE: 14.459880704006723  -Train Accuracy:  0.92121214\n",
      "epoch:  669  -  cost: 0.23313946  -MSE: 15.203082535803967  -Train Accuracy:  0.93333334\n",
      "epoch:  670  -  cost: 0.23223169  -MSE: 14.491733401092704  -Train Accuracy:  0.92121214\n",
      "epoch:  671  -  cost: 0.23284535  -MSE: 15.25460873212923  -Train Accuracy:  0.93333334\n",
      "epoch:  672  -  cost: 0.23208949  -MSE: 14.522480057806671  -Train Accuracy:  0.92121214\n",
      "epoch:  673  -  cost: 0.23323114  -MSE: 15.333648558989651  -Train Accuracy:  0.93333334\n",
      "epoch:  674  -  cost: 0.23277634  -MSE: 14.539716208144242  -Train Accuracy:  0.91515154\n",
      "epoch:  675  -  cost: 0.2335665  -MSE: 15.342288591509043  -Train Accuracy:  0.93333334\n",
      "epoch:  676  -  cost: 0.23241529  -MSE: 14.55215049128309  -Train Accuracy:  0.91515154\n",
      "epoch:  677  -  cost: 0.23357563  -MSE: 15.413129783622376  -Train Accuracy:  0.92727274\n",
      "epoch:  678  -  cost: 0.23293304  -MSE: 14.566020009521875  -Train Accuracy:  0.91515154\n",
      "epoch:  679  -  cost: 0.23476306  -MSE: 15.48483826151796  -Train Accuracy:  0.92121214\n",
      "epoch:  680  -  cost: 0.23440045  -MSE: 14.578080435330744  -Train Accuracy:  0.90909094\n",
      "epoch:  681  -  cost: 0.2366628  -MSE: 15.554672553496559  -Train Accuracy:  0.92121214\n",
      "epoch:  682  -  cost: 0.23769416  -MSE: 14.525535691567267  -Train Accuracy:  0.90909094\n",
      "epoch:  683  -  cost: 0.24024028  -MSE: 15.631617554882903  -Train Accuracy:  0.90909094\n",
      "epoch:  684  -  cost: 0.240893  -MSE: 14.521067125830966  -Train Accuracy:  0.9030303\n",
      "epoch:  685  -  cost: 0.24264467  -MSE: 15.667215684773815  -Train Accuracy:  0.9030303\n",
      "epoch:  686  -  cost: 0.24223752  -MSE: 14.526552451330232  -Train Accuracy:  0.9030303\n",
      "epoch:  687  -  cost: 0.24286069  -MSE: 15.680697690582187  -Train Accuracy:  0.8969697\n",
      "epoch:  688  -  cost: 0.24094135  -MSE: 14.5507086547644  -Train Accuracy:  0.9030303\n",
      "epoch:  689  -  cost: 0.24179794  -MSE: 15.691597963491843  -Train Accuracy:  0.9030303\n",
      "epoch:  690  -  cost: 0.23983987  -MSE: 14.559917127639588  -Train Accuracy:  0.9030303\n",
      "epoch:  691  -  cost: 0.24170181  -MSE: 15.707833142488084  -Train Accuracy:  0.9030303\n",
      "epoch:  692  -  cost: 0.24058285  -MSE: 14.540796546475349  -Train Accuracy:  0.9030303\n",
      "epoch:  693  -  cost: 0.24149212  -MSE: 15.708941595507802  -Train Accuracy:  0.8969697\n",
      "epoch:  694  -  cost: 0.24065237  -MSE: 14.513432985002034  -Train Accuracy:  0.9030303\n",
      "epoch:  695  -  cost: 0.24177052  -MSE: 15.721562117456969  -Train Accuracy:  0.8969697\n",
      "epoch:  696  -  cost: 0.24041724  -MSE: 14.526363314429606  -Train Accuracy:  0.9030303\n",
      "epoch:  697  -  cost: 0.2400363  -MSE: 15.703574711564526  -Train Accuracy:  0.9030303\n",
      "epoch:  698  -  cost: 0.23846139  -MSE: 14.560621602590052  -Train Accuracy:  0.9030303\n",
      "epoch:  699  -  cost: 0.23808573  -MSE: 15.730411178547891  -Train Accuracy:  0.90909094\n",
      "epoch:  700  -  cost: 0.23556556  -MSE: 14.624753287944936  -Train Accuracy:  0.9030303\n",
      "epoch:  701  -  cost: 0.23450717  -MSE: 15.719523476971052  -Train Accuracy:  0.91515154\n",
      "epoch:  702  -  cost: 0.23157027  -MSE: 14.633522545598472  -Train Accuracy:  0.90909094\n",
      "epoch:  703  -  cost: 0.23109998  -MSE: 15.660274135437227  -Train Accuracy:  0.92121214\n",
      "epoch:  704  -  cost: 0.22886676  -MSE: 14.641393307519085  -Train Accuracy:  0.90909094\n",
      "epoch:  705  -  cost: 0.22835402  -MSE: 15.625299928479095  -Train Accuracy:  0.92727274\n",
      "epoch:  706  -  cost: 0.22606269  -MSE: 14.654735186750857  -Train Accuracy:  0.92121214\n",
      "epoch:  707  -  cost: 0.22601004  -MSE: 15.601999911617233  -Train Accuracy:  0.93333334\n",
      "epoch:  708  -  cost: 0.22418767  -MSE: 14.669134215895415  -Train Accuracy:  0.91515154\n",
      "epoch:  709  -  cost: 0.22392257  -MSE: 15.576876692527115  -Train Accuracy:  0.93333334\n",
      "epoch:  710  -  cost: 0.22191083  -MSE: 14.683770321940514  -Train Accuracy:  0.92727274\n",
      "epoch:  711  -  cost: 0.22175284  -MSE: 15.55636332975826  -Train Accuracy:  0.93333334\n",
      "epoch:  712  -  cost: 0.22017431  -MSE: 14.7066611895115  -Train Accuracy:  0.92727274\n",
      "epoch:  713  -  cost: 0.22004616  -MSE: 15.536593009023523  -Train Accuracy:  0.93333334\n",
      "epoch:  714  -  cost: 0.2184499  -MSE: 14.74726682370806  -Train Accuracy:  0.92727274\n",
      "epoch:  715  -  cost: 0.21881594  -MSE: 15.586279289798307  -Train Accuracy:  0.93939394\n",
      "epoch:  716  -  cost: 0.21808802  -MSE: 14.727866934472807  -Train Accuracy:  0.92727274\n",
      "epoch:  717  -  cost: 0.21789229  -MSE: 15.55157240363673  -Train Accuracy:  0.93939394\n",
      "epoch:  718  -  cost: 0.21698979  -MSE: 14.750976004770594  -Train Accuracy:  0.92727274\n",
      "epoch:  719  -  cost: 0.21743803  -MSE: 15.597218504526793  -Train Accuracy:  0.93939394\n",
      "epoch:  720  -  cost: 0.21670587  -MSE: 14.768674313108146  -Train Accuracy:  0.92727274\n",
      "epoch:  721  -  cost: 0.21675721  -MSE: 15.583711553487195  -Train Accuracy:  0.93939394\n",
      "epoch:  722  -  cost: 0.21607989  -MSE: 14.74751991450041  -Train Accuracy:  0.92727274\n",
      "epoch:  723  -  cost: 0.21684977  -MSE: 15.629040259706565  -Train Accuracy:  0.93939394\n",
      "epoch:  724  -  cost: 0.21651047  -MSE: 14.788446764739811  -Train Accuracy:  0.92727274\n",
      "epoch:  725  -  cost: 0.21688223  -MSE: 15.665517617101127  -Train Accuracy:  0.93939394\n",
      "epoch:  726  -  cost: 0.21707681  -MSE: 14.80024377881092  -Train Accuracy:  0.92121214\n",
      "epoch:  727  -  cost: 0.2172688  -MSE: 15.704076804512562  -Train Accuracy:  0.93939394\n",
      "epoch:  728  -  cost: 0.21708478  -MSE: 14.794395355911083  -Train Accuracy:  0.92121214\n",
      "epoch:  729  -  cost: 0.21765216  -MSE: 15.72671920228164  -Train Accuracy:  0.93939394\n",
      "epoch:  730  -  cost: 0.21721373  -MSE: 14.82790526382851  -Train Accuracy:  0.92121214\n",
      "epoch:  731  -  cost: 0.2175603  -MSE: 15.77667557484725  -Train Accuracy:  0.93333334\n",
      "epoch:  732  -  cost: 0.21728742  -MSE: 14.824085600013161  -Train Accuracy:  0.92121214\n",
      "epoch:  733  -  cost: 0.21718496  -MSE: 15.775053658051867  -Train Accuracy:  0.93333334\n",
      "epoch:  734  -  cost: 0.2160132  -MSE: 14.817890827982529  -Train Accuracy:  0.92121214\n",
      "epoch:  735  -  cost: 0.21594281  -MSE: 15.746525230378424  -Train Accuracy:  0.93939394\n",
      "epoch:  736  -  cost: 0.2146268  -MSE: 14.847730364900187  -Train Accuracy:  0.92121214\n",
      "epoch:  737  -  cost: 0.21490265  -MSE: 15.791104506982766  -Train Accuracy:  0.93939394\n",
      "epoch:  738  -  cost: 0.21361193  -MSE: 14.852184796863005  -Train Accuracy:  0.92121214\n",
      "epoch:  739  -  cost: 0.21306531  -MSE: 15.746682383535084  -Train Accuracy:  0.93939394\n",
      "epoch:  740  -  cost: 0.21208075  -MSE: 14.860381051395802  -Train Accuracy:  0.92121214\n",
      "epoch:  741  -  cost: 0.21141627  -MSE: 15.71584746862049  -Train Accuracy:  0.93939394\n",
      "epoch:  742  -  cost: 0.21032895  -MSE: 14.88770016427113  -Train Accuracy:  0.92727274\n",
      "epoch:  743  -  cost: 0.21000534  -MSE: 15.745362558594165  -Train Accuracy:  0.93939394\n",
      "epoch:  744  -  cost: 0.20827815  -MSE: 14.94242595995859  -Train Accuracy:  0.92727274\n",
      "epoch:  745  -  cost: 0.20744659  -MSE: 15.707760714839175  -Train Accuracy:  0.93939394\n",
      "epoch:  746  -  cost: 0.20645021  -MSE: 14.96355139435519  -Train Accuracy:  0.95757574\n",
      "epoch:  747  -  cost: 0.20563674  -MSE: 15.711260231262216  -Train Accuracy:  0.93939394\n",
      "epoch:  748  -  cost: 0.20428504  -MSE: 15.022460726030166  -Train Accuracy:  0.96363634\n",
      "epoch:  749  -  cost: 0.20374094  -MSE: 15.706847160139422  -Train Accuracy:  0.93939394\n",
      "epoch:  750  -  cost: 0.20361698  -MSE: 15.011250434282829  -Train Accuracy:  0.96363634\n",
      "epoch:  751  -  cost: 0.20310967  -MSE: 15.720706594532263  -Train Accuracy:  0.93939394\n",
      "epoch:  752  -  cost: 0.20305562  -MSE: 15.03178715305433  -Train Accuracy:  0.96363634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  753  -  cost: 0.2024713  -MSE: 15.741971395200535  -Train Accuracy:  0.93939394\n",
      "epoch:  754  -  cost: 0.20140909  -MSE: 15.102032668916568  -Train Accuracy:  0.95757574\n",
      "epoch:  755  -  cost: 0.20064637  -MSE: 15.745579098819782  -Train Accuracy:  0.94545454\n",
      "epoch:  756  -  cost: 0.20075855  -MSE: 15.085379396189134  -Train Accuracy:  0.96363634\n",
      "epoch:  757  -  cost: 0.20025173  -MSE: 15.772342995003978  -Train Accuracy:  0.94545454\n",
      "epoch:  758  -  cost: 0.19921288  -MSE: 15.18705568234823  -Train Accuracy:  0.969697\n",
      "epoch:  759  -  cost: 0.1988297  -MSE: 15.808311877299301  -Train Accuracy:  0.95151514\n",
      "epoch:  760  -  cost: 0.19874904  -MSE: 15.182110773908086  -Train Accuracy:  0.969697\n",
      "epoch:  761  -  cost: 0.19829705  -MSE: 15.811959132907656  -Train Accuracy:  0.95151514\n",
      "epoch:  762  -  cost: 0.19803074  -MSE: 15.214400686269869  -Train Accuracy:  0.969697\n",
      "epoch:  763  -  cost: 0.19752914  -MSE: 15.838166246416035  -Train Accuracy:  0.95151514\n",
      "epoch:  764  -  cost: 0.19660766  -MSE: 15.281328218321088  -Train Accuracy:  0.969697\n",
      "epoch:  765  -  cost: 0.19637002  -MSE: 15.868316255393836  -Train Accuracy:  0.96363634\n",
      "epoch:  766  -  cost: 0.19621843  -MSE: 15.281266252815223  -Train Accuracy:  0.969697\n",
      "epoch:  767  -  cost: 0.19570352  -MSE: 15.887020643530656  -Train Accuracy:  0.96363634\n",
      "epoch:  768  -  cost: 0.19569473  -MSE: 15.291756963912938  -Train Accuracy:  0.969697\n",
      "epoch:  769  -  cost: 0.19531104  -MSE: 15.911140673572293  -Train Accuracy:  0.96363634\n",
      "epoch:  770  -  cost: 0.1943739  -MSE: 15.393124214294527  -Train Accuracy:  0.969697\n",
      "epoch:  771  -  cost: 0.194085  -MSE: 15.965471809909072  -Train Accuracy:  0.96363634\n",
      "epoch:  772  -  cost: 0.19407272  -MSE: 15.388063913940139  -Train Accuracy:  0.969697\n",
      "epoch:  773  -  cost: 0.19361848  -MSE: 15.98942948528811  -Train Accuracy:  0.96363634\n",
      "epoch:  774  -  cost: 0.19349067  -MSE: 15.422137382282617  -Train Accuracy:  0.969697\n",
      "epoch:  775  -  cost: 0.19304605  -MSE: 16.01219320829235  -Train Accuracy:  0.96363634\n",
      "epoch:  776  -  cost: 0.1922324  -MSE: 15.489278600563331  -Train Accuracy:  0.9757576\n",
      "epoch:  777  -  cost: 0.19203568  -MSE: 16.031887825333314  -Train Accuracy:  0.96363634\n",
      "epoch:  778  -  cost: 0.1917743  -MSE: 15.49210780759174  -Train Accuracy:  0.9757576\n",
      "epoch:  779  -  cost: 0.1914817  -MSE: 16.071859274383787  -Train Accuracy:  0.96363634\n",
      "epoch:  780  -  cost: 0.1915705  -MSE: 15.511512322426531  -Train Accuracy:  0.9757576\n",
      "epoch:  781  -  cost: 0.19122091  -MSE: 16.088804997089152  -Train Accuracy:  0.96363634\n",
      "epoch:  782  -  cost: 0.19047087  -MSE: 15.597960052509249  -Train Accuracy:  0.9757576\n",
      "epoch:  783  -  cost: 0.19033255  -MSE: 16.146011512488123  -Train Accuracy:  0.96363634\n",
      "epoch:  784  -  cost: 0.19033255  -MSE: 15.579394798210496  -Train Accuracy:  0.9757576\n",
      "epoch:  785  -  cost: 0.19008566  -MSE: 16.167309594672616  -Train Accuracy:  0.96363634\n",
      "epoch:  786  -  cost: 0.189994  -MSE: 15.611949729339651  -Train Accuracy:  0.9757576\n",
      "epoch:  787  -  cost: 0.1897792  -MSE: 16.20090941758534  -Train Accuracy:  0.96363634\n",
      "epoch:  788  -  cost: 0.18990706  -MSE: 15.621058917569583  -Train Accuracy:  0.9757576\n",
      "epoch:  789  -  cost: 0.18969746  -MSE: 16.248008106858443  -Train Accuracy:  0.96363634\n",
      "epoch:  790  -  cost: 0.189162  -MSE: 15.70052256832682  -Train Accuracy:  0.9757576\n",
      "epoch:  791  -  cost: 0.18892103  -MSE: 16.257857702585344  -Train Accuracy:  0.96363634\n",
      "epoch:  792  -  cost: 0.1887217  -MSE: 15.701617466856103  -Train Accuracy:  0.9757576\n",
      "epoch:  793  -  cost: 0.18852411  -MSE: 16.318254905324547  -Train Accuracy:  0.96363634\n",
      "epoch:  794  -  cost: 0.18858734  -MSE: 15.712429402665299  -Train Accuracy:  0.9757576\n",
      "epoch:  795  -  cost: 0.1886061  -MSE: 16.358484850524118  -Train Accuracy:  0.96363634\n",
      "epoch:  796  -  cost: 0.18796268  -MSE: 15.77859455115781  -Train Accuracy:  0.9757576\n",
      "epoch:  797  -  cost: 0.18784729  -MSE: 16.4019602601622  -Train Accuracy:  0.96363634\n",
      "epoch:  798  -  cost: 0.18778443  -MSE: 15.787768104948471  -Train Accuracy:  0.9757576\n",
      "epoch:  799  -  cost: 0.18764691  -MSE: 16.44927561515961  -Train Accuracy:  0.96363634\n",
      "epoch:  800  -  cost: 0.18760301  -MSE: 15.817326949641252  -Train Accuracy:  0.9757576\n",
      "epoch:  801  -  cost: 0.18744533  -MSE: 16.478925487805316  -Train Accuracy:  0.95757574\n",
      "epoch:  802  -  cost: 0.1874708  -MSE: 15.814628923814471  -Train Accuracy:  0.9757576\n",
      "epoch:  803  -  cost: 0.18745962  -MSE: 16.495398177273916  -Train Accuracy:  0.95757574\n",
      "epoch:  804  -  cost: 0.18633428  -MSE: 15.908032487023268  -Train Accuracy:  0.9757576\n",
      "epoch:  805  -  cost: 0.18625216  -MSE: 16.547264611476628  -Train Accuracy:  0.96363634\n",
      "epoch:  806  -  cost: 0.18603621  -MSE: 15.903952000122942  -Train Accuracy:  0.9757576\n",
      "epoch:  807  -  cost: 0.18606858  -MSE: 16.59594102987243  -Train Accuracy:  0.95757574\n",
      "epoch:  808  -  cost: 0.18610677  -MSE: 15.9072338816642  -Train Accuracy:  0.9757576\n",
      "epoch:  809  -  cost: 0.18642448  -MSE: 16.622943081539038  -Train Accuracy:  0.95757574\n",
      "epoch:  810  -  cost: 0.18651974  -MSE: 15.921133866157598  -Train Accuracy:  0.9757576\n",
      "epoch:  811  -  cost: 0.1866583  -MSE: 16.67240625852137  -Train Accuracy:  0.95151514\n",
      "epoch:  812  -  cost: 0.1864946  -MSE: 15.962944738152592  -Train Accuracy:  0.9757576\n",
      "epoch:  813  -  cost: 0.1866081  -MSE: 16.735665346089398  -Train Accuracy:  0.94545454\n",
      "epoch:  814  -  cost: 0.1865745  -MSE: 15.971715842965677  -Train Accuracy:  0.969697\n",
      "epoch:  815  -  cost: 0.18681602  -MSE: 16.797597343610896  -Train Accuracy:  0.93939394\n",
      "epoch:  816  -  cost: 0.18640088  -MSE: 16.000419747272485  -Train Accuracy:  0.969697\n",
      "epoch:  817  -  cost: 0.18662672  -MSE: 16.841829998811182  -Train Accuracy:  0.93939394\n",
      "epoch:  818  -  cost: 0.1865096  -MSE: 16.02987154170275  -Train Accuracy:  0.969697\n",
      "epoch:  819  -  cost: 0.18679966  -MSE: 16.87561293655941  -Train Accuracy:  0.93939394\n",
      "epoch:  820  -  cost: 0.18639024  -MSE: 16.05524959124754  -Train Accuracy:  0.96363634\n",
      "epoch:  821  -  cost: 0.18662849  -MSE: 16.941232106046613  -Train Accuracy:  0.93939394\n",
      "epoch:  822  -  cost: 0.18606886  -MSE: 16.091212956986297  -Train Accuracy:  0.96363634\n",
      "epoch:  823  -  cost: 0.1863482  -MSE: 16.984632014471384  -Train Accuracy:  0.93939394\n",
      "epoch:  824  -  cost: 0.18639676  -MSE: 16.10456000286064  -Train Accuracy:  0.96363634\n",
      "epoch:  825  -  cost: 0.1870742  -MSE: 17.049276949614644  -Train Accuracy:  0.93939394\n",
      "epoch:  826  -  cost: 0.18635112  -MSE: 16.134408187945105  -Train Accuracy:  0.95151514\n",
      "epoch:  827  -  cost: 0.1867343  -MSE: 17.10304207640897  -Train Accuracy:  0.93939394\n",
      "epoch:  828  -  cost: 0.18655747  -MSE: 16.17025647651327  -Train Accuracy:  0.95151514\n",
      "epoch:  829  -  cost: 0.18702713  -MSE: 17.19006028154817  -Train Accuracy:  0.93939394\n",
      "epoch:  830  -  cost: 0.1864181  -MSE: 16.221828613278348  -Train Accuracy:  0.95151514\n",
      "epoch:  831  -  cost: 0.18705298  -MSE: 17.256350737985  -Train Accuracy:  0.93939394\n",
      "epoch:  832  -  cost: 0.18632294  -MSE: 16.260928960260724  -Train Accuracy:  0.95151514\n",
      "epoch:  833  -  cost: 0.18720186  -MSE: 17.313300332370186  -Train Accuracy:  0.93939394\n",
      "epoch:  834  -  cost: 0.18671322  -MSE: 16.294828296037174  -Train Accuracy:  0.95151514\n",
      "epoch:  835  -  cost: 0.1873466  -MSE: 17.362235184975173  -Train Accuracy:  0.93939394\n",
      "epoch:  836  -  cost: 0.18664952  -MSE: 16.343398228384398  -Train Accuracy:  0.95151514\n",
      "epoch:  837  -  cost: 0.18721172  -MSE: 17.444925429882865  -Train Accuracy:  0.93939394\n",
      "epoch:  838  -  cost: 0.18631865  -MSE: 16.384561510683522  -Train Accuracy:  0.95151514\n",
      "epoch:  839  -  cost: 0.18683045  -MSE: 17.486774595238405  -Train Accuracy:  0.93939394\n",
      "epoch:  840  -  cost: 0.18508364  -MSE: 16.475402404881866  -Train Accuracy:  0.95151514\n",
      "epoch:  841  -  cost: 0.18529673  -MSE: 17.54288765761615  -Train Accuracy:  0.93939394\n",
      "epoch:  842  -  cost: 0.18383983  -MSE: 16.5044680380977  -Train Accuracy:  0.95151514\n",
      "epoch:  843  -  cost: 0.18418261  -MSE: 17.531323470988298  -Train Accuracy:  0.93939394\n",
      "epoch:  844  -  cost: 0.18287058  -MSE: 16.54862673636033  -Train Accuracy:  0.95151514\n",
      "epoch:  845  -  cost: 0.18275268  -MSE: 17.557165221586818  -Train Accuracy:  0.93939394\n",
      "epoch:  846  -  cost: 0.18147847  -MSE: 16.610625301574018  -Train Accuracy:  0.95757574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  847  -  cost: 0.18158107  -MSE: 17.6032319100495  -Train Accuracy:  0.93939394\n",
      "epoch:  848  -  cost: 0.18052267  -MSE: 16.646751773171488  -Train Accuracy:  0.96363634\n",
      "epoch:  849  -  cost: 0.18040723  -MSE: 17.624431684855182  -Train Accuracy:  0.93939394\n",
      "epoch:  850  -  cost: 0.17958082  -MSE: 16.703768843912695  -Train Accuracy:  0.96363634\n",
      "epoch:  851  -  cost: 0.1793256  -MSE: 17.614161300217365  -Train Accuracy:  0.93939394\n",
      "epoch:  852  -  cost: 0.17840928  -MSE: 16.71732476830273  -Train Accuracy:  0.969697\n",
      "epoch:  853  -  cost: 0.17805159  -MSE: 17.638453093062523  -Train Accuracy:  0.94545454\n",
      "epoch:  854  -  cost: 0.17717378  -MSE: 16.743729336204165  -Train Accuracy:  0.969697\n",
      "epoch:  855  -  cost: 0.17697872  -MSE: 17.660980275047688  -Train Accuracy:  0.95151514\n",
      "epoch:  856  -  cost: 0.17545073  -MSE: 16.879861052599168  -Train Accuracy:  0.9757576\n",
      "epoch:  857  -  cost: 0.1751867  -MSE: 17.693405276617867  -Train Accuracy:  0.96363634\n",
      "epoch:  858  -  cost: 0.17448898  -MSE: 16.87182793349631  -Train Accuracy:  0.9757576\n",
      "epoch:  859  -  cost: 0.1744903  -MSE: 17.713338848503753  -Train Accuracy:  0.96363634\n",
      "epoch:  860  -  cost: 0.17402942  -MSE: 16.935177752038168  -Train Accuracy:  0.9757576\n",
      "epoch:  861  -  cost: 0.173848  -MSE: 17.77416843943269  -Train Accuracy:  0.96363634\n",
      "epoch:  862  -  cost: 0.17323105  -MSE: 16.961104983642425  -Train Accuracy:  0.9757576\n",
      "epoch:  863  -  cost: 0.173137  -MSE: 17.80554791119448  -Train Accuracy:  0.96363634\n",
      "epoch:  864  -  cost: 0.17273797  -MSE: 17.033268645613074  -Train Accuracy:  0.9757576\n",
      "epoch:  865  -  cost: 0.1722711  -MSE: 17.813112862341058  -Train Accuracy:  0.969697\n",
      "epoch:  866  -  cost: 0.17185792  -MSE: 17.02340224396209  -Train Accuracy:  0.9757576\n",
      "epoch:  867  -  cost: 0.17164779  -MSE: 17.848115656781445  -Train Accuracy:  0.9757576\n",
      "epoch:  868  -  cost: 0.17120185  -MSE: 17.077353688388815  -Train Accuracy:  0.9757576\n",
      "epoch:  869  -  cost: 0.17076483  -MSE: 17.878195648503308  -Train Accuracy:  0.9757576\n",
      "epoch:  870  -  cost: 0.1703706  -MSE: 17.12943381208371  -Train Accuracy:  0.9757576\n",
      "epoch:  871  -  cost: 0.16999038  -MSE: 17.918511263513178  -Train Accuracy:  0.9757576\n",
      "epoch:  872  -  cost: 0.16971044  -MSE: 17.18629020385836  -Train Accuracy:  0.9757576\n",
      "epoch:  873  -  cost: 0.16909933  -MSE: 17.959794848921312  -Train Accuracy:  0.9757576\n",
      "epoch:  874  -  cost: 0.16890734  -MSE: 17.22426107993742  -Train Accuracy:  0.9757576\n",
      "epoch:  875  -  cost: 0.16835222  -MSE: 17.996505420337435  -Train Accuracy:  0.9757576\n",
      "epoch:  876  -  cost: 0.16829897  -MSE: 17.25973015816513  -Train Accuracy:  0.9757576\n",
      "epoch:  877  -  cost: 0.16768646  -MSE: 18.016532099116528  -Train Accuracy:  0.9757576\n",
      "epoch:  878  -  cost: 0.16762917  -MSE: 17.309139315297198  -Train Accuracy:  0.9757576\n",
      "epoch:  879  -  cost: 0.16715826  -MSE: 18.080016067176135  -Train Accuracy:  0.9757576\n",
      "epoch:  880  -  cost: 0.16704445  -MSE: 17.371351368165467  -Train Accuracy:  0.9757576\n",
      "epoch:  881  -  cost: 0.16678749  -MSE: 18.116807902521685  -Train Accuracy:  0.9757576\n",
      "epoch:  882  -  cost: 0.16661394  -MSE: 17.378591433095817  -Train Accuracy:  0.9757576\n",
      "epoch:  883  -  cost: 0.16643277  -MSE: 18.169985039405063  -Train Accuracy:  0.9757576\n",
      "epoch:  884  -  cost: 0.16638628  -MSE: 17.4369362111282  -Train Accuracy:  0.9757576\n",
      "epoch:  885  -  cost: 0.16625085  -MSE: 18.25023354362226  -Train Accuracy:  0.9757576\n",
      "epoch:  886  -  cost: 0.16631618  -MSE: 17.468877119955604  -Train Accuracy:  0.9757576\n",
      "epoch:  887  -  cost: 0.16620187  -MSE: 18.311890072931313  -Train Accuracy:  0.9757576\n",
      "epoch:  888  -  cost: 0.16628583  -MSE: 17.517607469339154  -Train Accuracy:  0.9757576\n",
      "epoch:  889  -  cost: 0.16614582  -MSE: 18.337766251643934  -Train Accuracy:  0.969697\n",
      "epoch:  890  -  cost: 0.16617839  -MSE: 17.51764820047675  -Train Accuracy:  0.9757576\n",
      "epoch:  891  -  cost: 0.16616024  -MSE: 18.40409271876572  -Train Accuracy:  0.969697\n",
      "epoch:  892  -  cost: 0.16644543  -MSE: 17.53308340798432  -Train Accuracy:  0.9757576\n",
      "epoch:  893  -  cost: 0.16658291  -MSE: 18.465591345570466  -Train Accuracy:  0.96363634\n",
      "epoch:  894  -  cost: 0.16680709  -MSE: 17.54574552611855  -Train Accuracy:  0.9757576\n",
      "epoch:  895  -  cost: 0.16686535  -MSE: 18.520097968894774  -Train Accuracy:  0.96363634\n",
      "epoch:  896  -  cost: 0.16709676  -MSE: 17.5363881356172  -Train Accuracy:  0.9757576\n",
      "epoch:  897  -  cost: 0.1674021  -MSE: 18.55767691131206  -Train Accuracy:  0.95757574\n",
      "epoch:  898  -  cost: 0.167572  -MSE: 17.527539213430046  -Train Accuracy:  0.969697\n",
      "epoch:  899  -  cost: 0.16802044  -MSE: 18.621161231992264  -Train Accuracy:  0.95757574\n",
      "epoch:  900  -  cost: 0.16802181  -MSE: 17.54366808628874  -Train Accuracy:  0.969697\n",
      "epoch:  901  -  cost: 0.16844255  -MSE: 18.673996383620466  -Train Accuracy:  0.95151514\n",
      "epoch:  902  -  cost: 0.16867042  -MSE: 17.53932564703154  -Train Accuracy:  0.95757574\n",
      "epoch:  903  -  cost: 0.16917132  -MSE: 18.709967802216603  -Train Accuracy:  0.95151514\n",
      "epoch:  904  -  cost: 0.16919337  -MSE: 17.506756262385327  -Train Accuracy:  0.95151514\n",
      "epoch:  905  -  cost: 0.16949682  -MSE: 18.737112754268416  -Train Accuracy:  0.95151514\n",
      "epoch:  906  -  cost: 0.16958015  -MSE: 17.485596498272006  -Train Accuracy:  0.95151514\n",
      "epoch:  907  -  cost: 0.16990133  -MSE: 18.76040435853705  -Train Accuracy:  0.94545454\n",
      "epoch:  908  -  cost: 0.16790299  -MSE: 17.564007354645096  -Train Accuracy:  0.95151514\n",
      "epoch:  909  -  cost: 0.16836704  -MSE: 18.799254051957917  -Train Accuracy:  0.95151514\n",
      "epoch:  910  -  cost: 0.16826685  -MSE: 17.537542041581915  -Train Accuracy:  0.95151514\n",
      "epoch:  911  -  cost: 0.16894802  -MSE: 18.83392185257097  -Train Accuracy:  0.94545454\n",
      "epoch:  912  -  cost: 0.168764  -MSE: 17.52774741786099  -Train Accuracy:  0.95151514\n",
      "epoch:  913  -  cost: 0.1692837  -MSE: 18.864104447564085  -Train Accuracy:  0.94545454\n",
      "epoch:  914  -  cost: 0.16901632  -MSE: 17.51699169384416  -Train Accuracy:  0.95151514\n",
      "epoch:  915  -  cost: 0.16984192  -MSE: 18.88879710843224  -Train Accuracy:  0.94545454\n",
      "epoch:  916  -  cost: 0.16934195  -MSE: 17.496581510916936  -Train Accuracy:  0.95151514\n",
      "epoch:  917  -  cost: 0.16989365  -MSE: 18.886724392510523  -Train Accuracy:  0.94545454\n",
      "epoch:  918  -  cost: 0.16929898  -MSE: 17.47486441605114  -Train Accuracy:  0.95151514\n",
      "epoch:  919  -  cost: 0.16983627  -MSE: 18.881172954891362  -Train Accuracy:  0.94545454\n",
      "epoch:  920  -  cost: 0.16785452  -MSE: 17.51416270217755  -Train Accuracy:  0.95151514\n",
      "epoch:  921  -  cost: 0.16833504  -MSE: 18.867313427427387  -Train Accuracy:  0.94545454\n",
      "epoch:  922  -  cost: 0.16715568  -MSE: 17.501672123257865  -Train Accuracy:  0.95151514\n",
      "epoch:  923  -  cost: 0.16771454  -MSE: 18.87420049416398  -Train Accuracy:  0.94545454\n",
      "epoch:  924  -  cost: 0.16655153  -MSE: 17.509909228535477  -Train Accuracy:  0.95151514\n",
      "epoch:  925  -  cost: 0.16676274  -MSE: 18.862923786760497  -Train Accuracy:  0.94545454\n",
      "epoch:  926  -  cost: 0.16580404  -MSE: 17.49853217056881  -Train Accuracy:  0.95151514\n",
      "epoch:  927  -  cost: 0.16587682  -MSE: 18.84731409858935  -Train Accuracy:  0.94545454\n",
      "epoch:  928  -  cost: 0.16502552  -MSE: 17.493451617486205  -Train Accuracy:  0.95151514\n",
      "epoch:  929  -  cost: 0.16496596  -MSE: 18.82999685458586  -Train Accuracy:  0.94545454\n",
      "epoch:  930  -  cost: 0.16288881  -MSE: 17.55124812027026  -Train Accuracy:  0.95757574\n",
      "epoch:  931  -  cost: 0.16311438  -MSE: 18.830611727401983  -Train Accuracy:  0.95757574\n",
      "epoch:  932  -  cost: 0.1622627  -MSE: 17.542448609680015  -Train Accuracy:  0.95757574\n",
      "epoch:  933  -  cost: 0.1623872  -MSE: 18.821818655125714  -Train Accuracy:  0.95757574\n",
      "epoch:  934  -  cost: 0.16161802  -MSE: 17.531350473571155  -Train Accuracy:  0.95757574\n",
      "epoch:  935  -  cost: 0.16173324  -MSE: 18.803330801897555  -Train Accuracy:  0.95757574\n",
      "epoch:  936  -  cost: 0.16096213  -MSE: 17.5306307252489  -Train Accuracy:  0.95757574\n",
      "epoch:  937  -  cost: 0.16072775  -MSE: 18.787593084427975  -Train Accuracy:  0.95757574\n",
      "epoch:  938  -  cost: 0.16005707  -MSE: 17.516484465457857  -Train Accuracy:  0.95757574\n",
      "epoch:  939  -  cost: 0.1598894  -MSE: 18.75369040764878  -Train Accuracy:  0.95757574\n",
      "epoch:  940  -  cost: 0.15905829  -MSE: 17.534987104350616  -Train Accuracy:  0.95757574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  941  -  cost: 0.15878084  -MSE: 18.746323084181434  -Train Accuracy:  0.95757574\n",
      "epoch:  942  -  cost: 0.15794294  -MSE: 17.539002143093803  -Train Accuracy:  0.96363634\n",
      "epoch:  943  -  cost: 0.15765399  -MSE: 18.731264685189423  -Train Accuracy:  0.96363634\n",
      "epoch:  944  -  cost: 0.15647139  -MSE: 17.55207331807104  -Train Accuracy:  0.96363634\n",
      "epoch:  945  -  cost: 0.15613456  -MSE: 18.69618390742577  -Train Accuracy:  0.96363634\n",
      "epoch:  946  -  cost: 0.1539373  -MSE: 17.640082848016455  -Train Accuracy:  0.9757576\n",
      "epoch:  947  -  cost: 0.15356028  -MSE: 18.68664591748082  -Train Accuracy:  0.96363634\n",
      "epoch:  948  -  cost: 0.1525768  -MSE: 17.64224256167667  -Train Accuracy:  0.9757576\n",
      "epoch:  949  -  cost: 0.15200964  -MSE: 18.657491973152144  -Train Accuracy:  0.96363634\n",
      "epoch:  950  -  cost: 0.15158296  -MSE: 17.6528696617199  -Train Accuracy:  0.9757576\n",
      "epoch:  951  -  cost: 0.1508527  -MSE: 18.64068563929477  -Train Accuracy:  0.96363634\n",
      "epoch:  952  -  cost: 0.15041164  -MSE: 17.68127536817937  -Train Accuracy:  0.9757576\n",
      "epoch:  953  -  cost: 0.1498303  -MSE: 18.630484265474678  -Train Accuracy:  0.96363634\n",
      "epoch:  954  -  cost: 0.1486902  -MSE: 17.74345232078691  -Train Accuracy:  0.9757576\n",
      "epoch:  955  -  cost: 0.1481853  -MSE: 18.625501759843026  -Train Accuracy:  0.969697\n",
      "epoch:  956  -  cost: 0.14791763  -MSE: 17.72688103038694  -Train Accuracy:  0.9757576\n",
      "epoch:  957  -  cost: 0.14750928  -MSE: 18.630116984326545  -Train Accuracy:  0.969697\n",
      "epoch:  958  -  cost: 0.14758022  -MSE: 17.70288284074803  -Train Accuracy:  0.9757576\n",
      "epoch:  959  -  cost: 0.14717355  -MSE: 18.626590502200308  -Train Accuracy:  0.969697\n",
      "epoch:  960  -  cost: 0.14735232  -MSE: 17.682886552807513  -Train Accuracy:  0.9757576\n",
      "epoch:  961  -  cost: 0.14703283  -MSE: 18.616738839227043  -Train Accuracy:  0.969697\n",
      "epoch:  962  -  cost: 0.1477555  -MSE: 17.601524039740166  -Train Accuracy:  0.9757576\n",
      "epoch:  963  -  cost: 0.14726965  -MSE: 18.587503227396812  -Train Accuracy:  0.969697\n",
      "epoch:  964  -  cost: 0.14624472  -MSE: 17.647886923547894  -Train Accuracy:  0.9757576\n",
      "epoch:  965  -  cost: 0.14680126  -MSE: 18.641940868610227  -Train Accuracy:  0.969697\n",
      "epoch:  966  -  cost: 0.14731352  -MSE: 17.56932993489975  -Train Accuracy:  0.969697\n",
      "epoch:  967  -  cost: 0.14840962  -MSE: 18.679997866280814  -Train Accuracy:  0.96363634\n",
      "epoch:  968  -  cost: 0.14898095  -MSE: 17.500210708991226  -Train Accuracy:  0.969697\n",
      "epoch:  969  -  cost: 0.15009438  -MSE: 18.714945562129035  -Train Accuracy:  0.96363634\n",
      "epoch:  970  -  cost: 0.15086001  -MSE: 17.434694824671737  -Train Accuracy:  0.96363634\n",
      "epoch:  971  -  cost: 0.1512685  -MSE: 18.72095921087262  -Train Accuracy:  0.95757574\n",
      "epoch:  972  -  cost: 0.1515591  -MSE: 17.387052138333832  -Train Accuracy:  0.95757574\n",
      "epoch:  973  -  cost: 0.1522338  -MSE: 18.700919505128343  -Train Accuracy:  0.95757574\n",
      "epoch:  974  -  cost: 0.1521185  -MSE: 17.331293599223862  -Train Accuracy:  0.95757574\n",
      "epoch:  975  -  cost: 0.15274426  -MSE: 18.70037166844214  -Train Accuracy:  0.95757574\n",
      "epoch:  976  -  cost: 0.1526846  -MSE: 17.275557515989195  -Train Accuracy:  0.95151514\n",
      "epoch:  977  -  cost: 0.15347911  -MSE: 18.675249352373857  -Train Accuracy:  0.95757574\n",
      "epoch:  978  -  cost: 0.15366888  -MSE: 17.213496799936127  -Train Accuracy:  0.94545454\n",
      "epoch:  979  -  cost: 0.15447749  -MSE: 18.692954858599634  -Train Accuracy:  0.95151514\n",
      "epoch:  980  -  cost: 0.1532507  -MSE: 17.231156563093496  -Train Accuracy:  0.94545454\n",
      "epoch:  981  -  cost: 0.155421  -MSE: 18.753676907390258  -Train Accuracy:  0.95151514\n",
      "epoch:  982  -  cost: 0.15687315  -MSE: 17.12326830745178  -Train Accuracy:  0.93333334\n",
      "epoch:  983  -  cost: 0.15729752  -MSE: 18.772061898604544  -Train Accuracy:  0.95151514\n",
      "epoch:  984  -  cost: 0.15740046  -MSE: 17.10041182497967  -Train Accuracy:  0.93333334\n",
      "epoch:  985  -  cost: 0.15771528  -MSE: 18.75206226227676  -Train Accuracy:  0.95151514\n",
      "epoch:  986  -  cost: 0.15721337  -MSE: 17.042082210514195  -Train Accuracy:  0.93333334\n",
      "epoch:  987  -  cost: 0.15732093  -MSE: 18.698715503378853  -Train Accuracy:  0.95151514\n",
      "epoch:  988  -  cost: 0.15643618  -MSE: 17.005769997698145  -Train Accuracy:  0.93333334\n",
      "epoch:  989  -  cost: 0.15630972  -MSE: 18.658323691226602  -Train Accuracy:  0.95151514\n",
      "epoch:  990  -  cost: 0.15384373  -MSE: 17.05205491577184  -Train Accuracy:  0.93939394\n",
      "epoch:  991  -  cost: 0.1555937  -MSE: 18.701520519196418  -Train Accuracy:  0.95151514\n",
      "epoch:  992  -  cost: 0.15585531  -MSE: 16.97682474193507  -Train Accuracy:  0.93333334\n",
      "epoch:  993  -  cost: 0.15566894  -MSE: 18.66295353543  -Train Accuracy:  0.95151514\n",
      "epoch:  994  -  cost: 0.15531424  -MSE: 16.9466952326053  -Train Accuracy:  0.93333334\n",
      "epoch:  995  -  cost: 0.15577286  -MSE: 18.655146574747207  -Train Accuracy:  0.95151514\n",
      "epoch:  996  -  cost: 0.1562624  -MSE: 16.872204494174838  -Train Accuracy:  0.93333334\n",
      "epoch:  997  -  cost: 0.15526722  -MSE: 18.624975891371395  -Train Accuracy:  0.95151514\n",
      "epoch:  998  -  cost: 0.15286882  -MSE: 16.954956702540432  -Train Accuracy:  0.93939394\n",
      "epoch:  999  -  cost: 0.153645  -MSE: 18.66297185682424  -Train Accuracy:  0.95151514\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cost and accuracy for each epoch\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "print(\"**\")\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x:train_x, y_true:train_y})\n",
    "    cost = sess.run(cost_function, feed_dict={x:train_x, y_true:train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    pred_y = sess.run(y,feed_dict={x:test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = sess.run(accuracy,feed_dict={x: train_x, y_true:train_y})\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch: ',epoch,' - ','cost:',cost,' -MSE:',mse_,\" -Train Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8333333\n"
     ]
    }
   ],
   "source": [
    "# Print the final accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print(\"Test Accuracy: \",(sess.run(accuracy, feed_dict={x:test_x, y_true:test_y})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18.6630\n"
     ]
    }
   ],
   "source": [
    "# Print final MSE\n",
    "pred_y = sess.run(y, feed_dict={x:test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "print(\"MSE: %.4f\"%sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c8f859dcc0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot MSE and accuracy graph\n",
    "plt.title(\"MSE\")\n",
    "plt.plot(mse_history,'r')\n",
    "plt.show()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(accuracy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
